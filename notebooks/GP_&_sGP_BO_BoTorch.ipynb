{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/utkarshp1161/Active-learning-in-microscopy/blob/main/notebooks/GP_&_sGP_BO_BoTorch.ipynb.ipynb)\n",
    "\n",
    "Tutorials for GP and structured "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBXRVrQFPaK4"
   },
   "source": [
    "# 1.Gaussian process-based Bayesian optimization\n",
    "\n",
    "- Rewritten in Gpytorch and Botorch by [Utkarsh Pratiush](https://github.com/utkarshp1161). [Originally in Gpax](https://github.com/SergeiVKalinin/ACerS_AE_2024/blob/main/1_GPax_GP_BO.ipynb) by [Maxim Ziatdinov](https://github.com/ziatdinovmax) and [SVK](https://github.com/SergeiVKalinin).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yaHz4Y58lzKx"
   },
   "source": [
    "## 1a. Install dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z0JUgY9jlyvc"
   },
   "outputs": [],
   "source": [
    "!pip install -q botorch==0.12.0\n",
    "!pip install -q gpytorch==1.13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nr7Y11r5CuC4"
   },
   "source": [
    "## 1b. Kernels in Gpytorch\n",
    "It can be tricky to define them from scratch as done below but off the shelf kernels can be directly used as well\n",
    "- from gpytorch.kernels import RBFKernel, ScaleKernel, MaternKernel\n",
    "- see https://docs.gpytorch.ai/en/latest/kernels.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "executionInfo": {
     "elapsed": 1396,
     "status": "ok",
     "timestamp": 1736875946177,
     "user": {
      "displayName": "Utkarsh Pratiush",
      "userId": "14303792046592850693"
     },
     "user_tz": -330
    },
    "id": "Tt-zOw-ryN8S",
    "outputId": "6f641eb6-ee45-4a77-db8e-290efe00d356"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import gpytorch\n",
    "from gpytorch.constraints import Positive\n",
    "import math\n",
    "\n",
    "class SquaredExponentialKernel(gpytorch.kernels.Kernel):\n",
    "    is_stationary = True\n",
    "\n",
    "    def __init__(self, variance_prior=None, length_prior=None,\n",
    "                 variance_constraint=None, length_constraint=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Register raw parameters\n",
    "        self.register_parameter(\n",
    "            name='raw_length',\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name='raw_variance',\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "\n",
    "        # Set constraints\n",
    "        if length_constraint is None:\n",
    "            length_constraint = Positive()\n",
    "        if variance_constraint is None:\n",
    "            variance_constraint = Positive()\n",
    "\n",
    "        self.register_constraint(\"raw_length\", length_constraint)\n",
    "        self.register_constraint(\"raw_variance\", variance_constraint)\n",
    "\n",
    "        # Set priors if any\n",
    "        if length_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"length_prior\",\n",
    "                length_prior,\n",
    "                lambda m: m.length,\n",
    "                lambda m, v: m._set_length(v),\n",
    "            )\n",
    "        if variance_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"variance_prior\",\n",
    "                variance_prior,\n",
    "                lambda m: m.variance,\n",
    "                lambda m, v: m._set_variance(v),\n",
    "            )\n",
    "\n",
    "    # Length scale property\n",
    "    @property\n",
    "    def length(self):\n",
    "        return self.raw_length_constraint.transform(self.raw_length)\n",
    "\n",
    "    @length.setter\n",
    "    def length(self, value):\n",
    "        return self._set_length(value)\n",
    "\n",
    "    def _set_length(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_length)\n",
    "        self.initialize(raw_length=self.raw_length_constraint.inverse_transform(value))\n",
    "\n",
    "    # Variance property\n",
    "    @property\n",
    "    def variance(self):\n",
    "        return self.raw_variance_constraint.transform(self.raw_variance)\n",
    "\n",
    "    @variance.setter\n",
    "    def variance(self, value):\n",
    "        return self._set_variance(value)\n",
    "\n",
    "    def _set_variance(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_variance)\n",
    "        self.initialize(raw_variance=self.raw_variance_constraint.inverse_transform(value))\n",
    "\n",
    "    def forward(self, x1, x2, **params):\n",
    "        # Scale by length\n",
    "        x1_ = x1.div(self.length)\n",
    "        x2_ = x2.div(self.length)\n",
    "\n",
    "        # Compute squared distance\n",
    "        squared_dist = self.covar_dist(x1_, x2_, **params).pow(2)\n",
    "\n",
    "        # Compute kernel\n",
    "        return self.variance * torch.exp(-0.5 * squared_dist)\n",
    "class RationalQuadraticKernel(gpytorch.kernels.Kernel):\n",
    "    is_stationary = True\n",
    "\n",
    "    def __init__(self, variance_prior=None, length_prior=None, alpha_prior=None,\n",
    "                 variance_constraint=None, length_constraint=None, alpha_constraint=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Register raw parameters\n",
    "        self.register_parameter(\n",
    "            name='raw_length',\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name='raw_variance',\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name='raw_alpha',\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "\n",
    "        # Set constraints\n",
    "        if length_constraint is None:\n",
    "            length_constraint = Positive()\n",
    "        if variance_constraint is None:\n",
    "            variance_constraint = Positive()\n",
    "        if alpha_constraint is None:\n",
    "            alpha_constraint = Positive()\n",
    "\n",
    "        self.register_constraint(\"raw_length\", length_constraint)\n",
    "        self.register_constraint(\"raw_variance\", variance_constraint)\n",
    "        self.register_constraint(\"raw_alpha\", alpha_constraint)\n",
    "\n",
    "        # Set priors if any\n",
    "        if length_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"length_prior\",\n",
    "                length_prior,\n",
    "                lambda m: m.length,\n",
    "                lambda m, v: m._set_length(v),\n",
    "            )\n",
    "        if variance_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"variance_prior\",\n",
    "                variance_prior,\n",
    "                lambda m: m.variance,\n",
    "                lambda m, v: m._set_variance(v),\n",
    "            )\n",
    "        if alpha_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"alpha_prior\",\n",
    "                alpha_prior,\n",
    "                lambda m: m.alpha,\n",
    "                lambda m, v: m._set_alpha(v),\n",
    "            )\n",
    "\n",
    "    # Length scale property\n",
    "    @property\n",
    "    def length(self):\n",
    "        return self.raw_length_constraint.transform(self.raw_length)\n",
    "\n",
    "    @length.setter\n",
    "    def length(self, value):\n",
    "        return self._set_length(value)\n",
    "\n",
    "    def _set_length(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_length)\n",
    "        self.initialize(raw_length=self.raw_length_constraint.inverse_transform(value))\n",
    "\n",
    "    # Variance property\n",
    "    @property\n",
    "    def variance(self):\n",
    "        return self.raw_variance_constraint.transform(self.raw_variance)\n",
    "\n",
    "    @variance.setter\n",
    "    def variance(self, value):\n",
    "        return self._set_variance(value)\n",
    "\n",
    "    def _set_variance(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_variance)\n",
    "        self.initialize(raw_variance=self.raw_variance_constraint.inverse_transform(value))\n",
    "\n",
    "    # Alpha property\n",
    "    @property\n",
    "    def alpha(self):\n",
    "        return self.raw_alpha_constraint.transform(self.raw_alpha)\n",
    "\n",
    "    @alpha.setter\n",
    "    def alpha(self, value):\n",
    "        return self._set_alpha(value)\n",
    "\n",
    "    def _set_alpha(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_alpha)\n",
    "        self.initialize(raw_alpha=self.raw_alpha_constraint.inverse_transform(value))\n",
    "\n",
    "    def forward(self, x1, x2, **params):\n",
    "        # Compute squared distance\n",
    "        squared_dist = self.covar_dist(x1, x2, **params).pow(2)\n",
    "\n",
    "        # Compute kernel\n",
    "        return self.variance * (1 + squared_dist / (2 * self.alpha * self.length**2))**(-self.alpha)\n",
    "class PeriodicKernel(gpytorch.kernels.Kernel):\n",
    "    is_stationary = True\n",
    "\n",
    "    def __init__(self, variance_prior=None, length_prior=None, period_prior=None,\n",
    "                 variance_constraint=None, length_constraint=None, period_constraint=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Register raw parameters\n",
    "        self.register_parameter(\n",
    "            name='raw_length',\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name='raw_variance',\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name='raw_period',\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "\n",
    "        # Set constraints\n",
    "        if length_constraint is None:\n",
    "            length_constraint = Positive()\n",
    "        if variance_constraint is None:\n",
    "            variance_constraint = Positive()\n",
    "        if period_constraint is None:\n",
    "            period_constraint = Positive()\n",
    "\n",
    "        self.register_constraint(\"raw_length\", length_constraint)\n",
    "        self.register_constraint(\"raw_variance\", variance_constraint)\n",
    "        self.register_constraint(\"raw_period\", period_constraint)\n",
    "\n",
    "        # Set priors if any\n",
    "        if length_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"length_prior\",\n",
    "                length_prior,\n",
    "                lambda m: m.length,\n",
    "                lambda m, v: m._set_length(v),\n",
    "            )\n",
    "        if variance_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"variance_prior\",\n",
    "                variance_prior,\n",
    "                lambda m: m.variance,\n",
    "                lambda m, v: m._set_variance(v),\n",
    "            )\n",
    "        if period_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"period_prior\",\n",
    "                period_prior,\n",
    "                lambda m: m.period,\n",
    "                lambda m, v: m._set_period(v),\n",
    "            )\n",
    "\n",
    "    # Length scale property\n",
    "    @property\n",
    "    def length(self):\n",
    "        return self.raw_length_constraint.transform(self.raw_length)\n",
    "\n",
    "    @length.setter\n",
    "    def length(self, value):\n",
    "        return self._set_length(value)\n",
    "\n",
    "    def _set_length(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_length)\n",
    "        self.initialize(raw_length=self.raw_length_constraint.inverse_transform(value))\n",
    "\n",
    "    # Variance property\n",
    "    @property\n",
    "    def variance(self):\n",
    "        return self.raw_variance_constraint.transform(self.raw_variance)\n",
    "\n",
    "    @variance.setter\n",
    "    def variance(self, value):\n",
    "        return self._set_variance(value)\n",
    "\n",
    "    def _set_variance(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_variance)\n",
    "        self.initialize(raw_variance=self.raw_variance_constraint.inverse_transform(value))\n",
    "\n",
    "    # Period property\n",
    "    @property\n",
    "    def period(self):\n",
    "        return self.raw_period_constraint.transform(self.raw_period)\n",
    "\n",
    "    @period.setter\n",
    "    def period(self, value):\n",
    "        return self._set_period(value)\n",
    "\n",
    "    def _set_period(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_period)\n",
    "        self.initialize(raw_period=self.raw_period_constraint.inverse_transform(value))\n",
    "\n",
    "    def forward(self, x1, x2, **params):\n",
    "        # Compute distance\n",
    "        dist = self.covar_dist(x1, x2, **params)\n",
    "\n",
    "        # Compute periodic kernel\n",
    "        sin_component = torch.sin(math.pi * dist / self.period)\n",
    "        exp_component = -2 * sin_component.pow(2) / self.length.pow(2)\n",
    "\n",
    "        return self.variance * torch.exp(exp_component)\n",
    "class MaternKernel(gpytorch.kernels.Kernel):\n",
    "    is_stationary = True\n",
    "\n",
    "    def __init__(self, variance_prior=None, length_prior=None,\n",
    "                 variance_constraint=None, length_constraint=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Register raw parameters\n",
    "        self.register_parameter(\n",
    "            name='raw_length',\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name='raw_variance',\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "\n",
    "        # Set constraints\n",
    "        if length_constraint is None:\n",
    "            length_constraint = Positive()\n",
    "        if variance_constraint is None:\n",
    "            variance_constraint = Positive()\n",
    "\n",
    "        self.register_constraint(\"raw_length\", length_constraint)\n",
    "        self.register_constraint(\"raw_variance\", variance_constraint)\n",
    "\n",
    "        # Set priors if any\n",
    "        if length_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"length_prior\",\n",
    "                length_prior,\n",
    "                lambda m: m.length,\n",
    "                lambda m, v: m._set_length(v),\n",
    "            )\n",
    "        if variance_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"variance_prior\",\n",
    "                variance_prior,\n",
    "                lambda m: m.variance,\n",
    "                lambda m, v: m._set_variance(v),\n",
    "            )\n",
    "\n",
    "    # Length scale property\n",
    "    @property\n",
    "    def length(self):\n",
    "        return self.raw_length_constraint.transform(self.raw_length)\n",
    "\n",
    "    @length.setter\n",
    "    def length(self, value):\n",
    "        return self._set_length(value)\n",
    "\n",
    "    def _set_length(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_length)\n",
    "        self.initialize(raw_length=self.raw_length_constraint.inverse_transform(value))\n",
    "\n",
    "    # Variance property\n",
    "    @property\n",
    "    def variance(self):\n",
    "        return self.raw_variance_constraint.transform(self.raw_variance)\n",
    "\n",
    "    @variance.setter\n",
    "    def variance(self, value):\n",
    "        return self._set_variance(value)\n",
    "\n",
    "    def _set_variance(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_variance)\n",
    "        self.initialize(raw_variance=self.raw_variance_constraint.inverse_transform(value))\n",
    "\n",
    "    def forward(self, x1, x2, **params):\n",
    "        # Compute distance\n",
    "        dist = self.covar_dist(x1, x2, **params)\n",
    "\n",
    "        # Scale by length\n",
    "        scaled_dist = dist.div(self.length)\n",
    "\n",
    "        # Compute Matern kernel (nu=3/2)\n",
    "        sqrt3 = torch.sqrt(torch.tensor(3.0))\n",
    "        return self.variance * (1 + sqrt3 * scaled_dist) * torch.exp(-sqrt3 * scaled_dist)\n",
    "\n",
    "# Create kernel instances\n",
    "rq_kernel = RationalQuadraticKernel()\n",
    "se_kernel = SquaredExponentialKernel()\n",
    "pe_kernel = PeriodicKernel()\n",
    "mt_kernel = MaternKernel()\n",
    "\n",
    "# Set parameters\n",
    "rq_kernel.length = 1.0\n",
    "rq_kernel.variance = 1.0\n",
    "rq_kernel.alpha = 1.0\n",
    "\n",
    "se_kernel.length = 1.0\n",
    "se_kernel.variance = 1.0\n",
    "\n",
    "pe_kernel.length = 1.0\n",
    "pe_kernel.variance = 1.0\n",
    "pe_kernel.period = 2.0\n",
    "\n",
    "mt_kernel.length = 1.0\n",
    "mt_kernel.variance = 1.0\n",
    "\n",
    "# Create distance matrix\n",
    "d = torch.linspace(0, 5, 400)#.view(-1, 1)\n",
    "zeros = torch.zeros_like(d)\n",
    "\n",
    "# Compute kernel values\n",
    "K_RQ = rq_kernel(d, zeros).evaluate().squeeze()\n",
    "K_SE = se_kernel(d, zeros).evaluate().squeeze()\n",
    "K_periodic = pe_kernel(d, zeros).evaluate().squeeze()\n",
    "K_Matern = mt_kernel(d, zeros).evaluate().squeeze()\n",
    "\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 7))\n",
    "# plot self terms - diagonal enteries\n",
    "plt.plot(d.numpy(), K_RQ.detach().numpy().diagonal(), label='Squared Exponential')\n",
    "plt.plot(d.numpy(), K_SE.detach().numpy().diagonal(), label='Rational Quadratic')\n",
    "plt.plot(d.numpy(), K_periodic.detach().numpy().diagonal(), label='Periodic')\n",
    "plt.plot(d.numpy(), K_Matern.detach().numpy().diagonal(), label='Matérn 3/2')\n",
    "\n",
    "plt.title('Kernel Comparison')\n",
    "plt.xlabel('Distance between points')\n",
    "plt.ylabel('Kernel value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1736875946177,
     "user": {
      "displayName": "Utkarsh Pratiush",
      "userId": "14303792046592850693"
     },
     "user_tz": -330
    },
    "id": "M0YSBMk7CbLh",
    "outputId": "907f8d76-160c-4e8f-f36d-0388a5e1d575"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import kv, gamma\n",
    "\n",
    "class MaternKernel(gpytorch.kernels.Kernel):\n",
    "    is_stationary = True\n",
    "\n",
    "    def __init__(self, nu=1.5, variance_prior=None, length_prior=None,\n",
    "                 variance_constraint=None, length_constraint=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.nu = nu\n",
    "\n",
    "        # Register raw parameters\n",
    "        self.register_parameter(\n",
    "            name='raw_length',\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name='raw_variance',\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "\n",
    "        # Set constraints\n",
    "        if length_constraint is None:\n",
    "            length_constraint = Positive()\n",
    "        if variance_constraint is None:\n",
    "            variance_constraint = Positive()\n",
    "\n",
    "        self.register_constraint(\"raw_length\", length_constraint)\n",
    "        self.register_constraint(\"raw_variance\", variance_constraint)\n",
    "\n",
    "        # Set priors if any\n",
    "        if length_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"length_prior\",\n",
    "                length_prior,\n",
    "                lambda m: m.length,\n",
    "                lambda m, v: m._set_length(v),\n",
    "            )\n",
    "        if variance_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"variance_prior\",\n",
    "                variance_prior,\n",
    "                lambda m: m.variance,\n",
    "                lambda m, v: m._set_variance(v),\n",
    "            )\n",
    "\n",
    "    @property\n",
    "    def length(self):\n",
    "        return self.raw_length_constraint.transform(self.raw_length)\n",
    "\n",
    "    @length.setter\n",
    "    def length(self, value):\n",
    "        return self._set_length(value)\n",
    "\n",
    "    def _set_length(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_length)\n",
    "        self.initialize(raw_length=self.raw_length_constraint.inverse_transform(value))\n",
    "\n",
    "    @property\n",
    "    def variance(self):\n",
    "        return self.raw_variance_constraint.transform(self.raw_variance)\n",
    "\n",
    "    @variance.setter\n",
    "    def variance(self, value):\n",
    "        return self._set_variance(value)\n",
    "\n",
    "    def _set_variance(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_variance)\n",
    "        self.initialize(raw_variance=self.raw_variance_constraint.inverse_transform(value))\n",
    "\n",
    "    def forward(self, x1, x2, **params):\n",
    "        distance = self.covar_dist(x1.div(self.length), x2.div(self.length), **params)\n",
    "\n",
    "        # Handle the zero distance case\n",
    "        eps = 1e-10\n",
    "        distance = distance.clamp(min=eps)\n",
    "\n",
    "        if self.nu == 0.5:\n",
    "            K = torch.exp(-distance)\n",
    "        elif self.nu == 1.5:\n",
    "            K = (1 + math.sqrt(3) * distance) * torch.exp(-math.sqrt(3) * distance)\n",
    "        elif self.nu == 2.5:\n",
    "            K = (1 + math.sqrt(5) * distance + 5/3 * distance**2) * torch.exp(-math.sqrt(5) * distance)\n",
    "        else:\n",
    "            raise ValueError(\"Only nu=0.5, 1.5, and 2.5 are supported\")\n",
    "\n",
    "        return self.variance * K\n",
    "\n",
    "# Settings for different ν values\n",
    "# Create different Matérn kernels\n",
    "kernel_05 = MaternKernel(nu=0.5)\n",
    "kernel_15 = MaternKernel(nu=1.5)\n",
    "kernel_25 = MaternKernel(nu=2.5)\n",
    "\n",
    "# Set parameters\n",
    "for kernel in [kernel_05, kernel_15, kernel_25]:\n",
    "    kernel.length = 1.0\n",
    "    kernel.variance = 1.0\n",
    "\n",
    "# Create distance matrix\n",
    "d = torch.linspace(0, 5, 400).view(-1, 1)\n",
    "zeros = torch.zeros_like(d)\n",
    "# Compute kernel values\n",
    "K_05 = kernel_05(d, zeros).evaluate().squeeze()\n",
    "K_15 = kernel_15(d, zeros).evaluate().squeeze()\n",
    "K_25 = kernel_25(d, zeros).evaluate().squeeze()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(d.numpy(), K_05.detach().numpy().diagonal() , c = \"b\", label='ν=0.5')\n",
    "plt.plot(d.numpy(), K_15.detach().numpy().diagonal() , c = \"g\", label='ν=1.5')\n",
    "plt.plot(d.numpy(), K_25.detach().numpy().diagonal() , c = \"r\", label='ν=2.5')\n",
    "plt.title('Matérn Kernel for Different Values of ν')\n",
    "plt.xlabel('Distance between points')\n",
    "plt.ylabel('Kernel value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuENb5_eCyPg"
   },
   "source": [
    "## 1c. GPs for different kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 11994,
     "status": "ok",
     "timestamp": 1736875958167,
     "user": {
      "displayName": "Utkarsh Pratiush",
      "userId": "14303792046592850693"
     },
     "user_tz": -330
    },
    "id": "UZ1YJg4FyxQr",
    "outputId": "5bbb721c-72e0-420c-c0f0-c9dfa33d3855"
   },
   "outputs": [],
   "source": [
    "# Generate data\n",
    "X = torch.linspace(-5, 5, 1000).view(-1, 1)\n",
    "\n",
    "# Compute kernel matrices\n",
    "K_SE = se_kernel(X, X).evaluate().squeeze().detach().numpy()\n",
    "K_RQ = rq_kernel(X, X).evaluate().squeeze().detach().numpy()\n",
    "K_P = pe_kernel(X, X).evaluate().squeeze().detach().numpy()\n",
    "K_M = mt_kernel(X, X) .evaluate().squeeze().detach().numpy() # Matérn kernel\n",
    "\n",
    "# Drawing samples from the GP prior\n",
    "np.random.seed(42)  # For reproducibility\n",
    "samples_SE = np.random.multivariate_normal(mean=np.zeros(X.shape[0]), cov=K_SE, size=3)\n",
    "samples_RQ = np.random.multivariate_normal(mean=np.zeros(X.shape[0]), cov=K_RQ, size=3)\n",
    "samples_P = np.random.multivariate_normal(mean=np.zeros(X.shape[0]), cov=K_P, size=3)\n",
    "samples_M = np.random.multivariate_normal(mean=np.zeros(X.shape[0]), cov=K_M, size=3)  # Samples for Matérn kernel\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(4, 1, figsize=(10, 20))  # Adjusted for an additional row\n",
    "\n",
    "for ax, samples, title in zip(axs, [samples_SE, samples_RQ, samples_P, samples_M], ['SE Kernel', 'RQ Kernel', 'Periodic Kernel', 'Matérn 3/2 Kernel']):\n",
    "    for i in range(samples.shape[0]):\n",
    "        ax.plot(X, samples[i], lw=2)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlim([-5, 5])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 853
    },
    "executionInfo": {
     "elapsed": 3515,
     "status": "ok",
     "timestamp": 1736875961673,
     "user": {
      "displayName": "Utkarsh Pratiush",
      "userId": "14303792046592850693"
     },
     "user_tz": -330
    },
    "id": "sTEyFnc2z7Oi",
    "outputId": "e2327072-cfa0-445e-d8a4-72f8b188a9ae"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a 2x2 subplot grid\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "# Plot each kernel matrix as an imshow\n",
    "axs[0, 0].imshow(K_SE)\n",
    "axs[0, 0].set_title('Squared Exponential Kernel')\n",
    "axs[0, 1].imshow(K_RQ)\n",
    "axs[0, 1].set_title('Rational Quadratic Kernel')\n",
    "axs[1, 0].imshow(K_P)\n",
    "axs[1, 0].set_title('Periodic Kernel')\n",
    "axs[1, 1].imshow(K_M)\n",
    "axs[1, 1].set_title('Matérn 3/2 Kernel')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Qv9tpGCab0E"
   },
   "source": [
    "## 1d. Define a data generation process (ground truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAejc4usmzxi"
   },
   "source": [
    "Let's define a function to be minimized and a function that emulates a noisy measurement:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkhH9rFHMlJ3"
   },
   "source": [
    "SVK Note: Here, the function is ground truth. This is how nature behaves, but we do not know it. Purpose of the experiment is either learn this function (EU aquisition function), or discover minimum of this function (UCB aquisition function). Note that parameter beta in UCB determines balance between the explorationa and exploitation (if we set beta to zero, we make algorithm greedy so it get trapped into whatever minimum it discovers first). Also note that the noise that we add is a measurement noise that we define a priori. Experimentalist does not know what it is - you actually aim to learn it from the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SS6wrbVHfp-N"
   },
   "outputs": [],
   "source": [
    "def func(x, y=1.2):\n",
    "    out = (\n",
    "        -20 * np.exp(-0.2 * np.sqrt(0.5 * (x**2 + y**2)))\n",
    "        - np.exp(0.5 * (np.cos(2 * np.pi * x) + np.cos(2 * np.pi * y)))\n",
    "        + np.e + 20\n",
    "    )\n",
    "    return out\n",
    "\n",
    "# Define measurement function that works with tensors\n",
    "def measure(x, noise=0.01):\n",
    "    \"\"\"Measure function with noise that works with torch tensors\"\"\"\n",
    "    if not torch.is_tensor(x):\n",
    "        x = torch.tensor(x, dtype=torch.double)\n",
    "    x = x.reshape(-1, 1)  # Ensure 2D tensor with shape (n, 1)\n",
    "\n",
    "    # Add noise using torch operations\n",
    "    noise = noise * torch.randn_like(x)#torch.randn_like(x)): Returns a tensor with the same size as input that is filled with random numbers from a normal distribution with mean 0 and variance 1\n",
    "\n",
    "    return func(x) + noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_lOdSM2m0WN"
   },
   "source": [
    "Next, we generate a few noisy observations of our function. We also plot the true function (\"ground truth\") to confirm the location of the minimum at $x=0$ but we are not going to use it anywhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "executionInfo": {
     "elapsed": 1146,
     "status": "ok",
     "timestamp": 1736875962812,
     "user": {
      "displayName": "Utkarsh Pratiush",
      "userId": "14303792046592850693"
     },
     "user_tz": -330
    },
    "id": "YU0DxM5UhSpd",
    "outputId": "d54d8b13-0581-471f-c835-137021be04d6"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "X_bounds = np.array([-2, 2])\n",
    "X = np.random.uniform(X_bounds[0], X_bounds[1], size=(2,))\n",
    "X = np.append(X, X_bounds)\n",
    "X = np.sort(X)\n",
    "y = measure(X, noise = 0.3)\n",
    "\n",
    "X_unmeasured = np.linspace(X_bounds[0], X_bounds[1], 200)\n",
    "ground_truth = measure(X_unmeasured, noise=0)\n",
    "\n",
    "\n",
    "_, ax = plt.subplots(dpi=100, figsize=(7, 5.5))\n",
    "ax.set_xlabel(\"$X$\", fontsize=16)\n",
    "ax.set_ylabel(\"$y$\", fontsize=16)\n",
    "ax.scatter(X, y, marker='x', c='k', s=64, zorder=1, label=\"Observations\", alpha=1.0)\n",
    "ax.plot(X_unmeasured, ground_truth, label='Ground truth')\n",
    "ax.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxMaENIclvNX"
   },
   "source": [
    "## 1e. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sP5CJNXIlvNX"
   },
   "outputs": [],
   "source": [
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.transforms import Standardize, Normalize\n",
    "# from gpytorch.kernels import RBFKernel, ScaleKernel\n",
    "from gpytorch.kernels import  ScaleKernel\n",
    "\n",
    "from gpytorch.constraints import GreaterThan\n",
    "\n",
    "class CustomGP(SingleTaskGP):\n",
    "    def __init__(self, train_X, train_Y, kernel, lengthscale_prior, outputscale_prior, noise_prior):\n",
    "        super().__init__(\n",
    "            train_X,\n",
    "            train_Y,\n",
    "            input_transform=Normalize(d=1),\n",
    "            outcome_transform=Standardize(m=1)\n",
    "        )\n",
    "        self.mean_module.constant.requires_grad_(False)\n",
    "\n",
    "        # Replace default kernel with custom kernel\n",
    "        self.covar_module = ScaleKernel(kernel)\n",
    "        \"\"\"\n",
    "        The ScaleKernel in this context serves as a wrapper around the base kernel\n",
    "        and introduces an additional learned parameter called the \"outputscale\"\n",
    "        \"\"\"\n",
    "\n",
    "        # Register priors\n",
    "        self.covar_module.base_kernel.register_prior(\n",
    "            \"lengthscale_prior\",\n",
    "            lengthscale_prior,\n",
    "            lambda module: module.lengthscale,\n",
    "            lambda module, value: module._set_lengthscale(value)\n",
    "        )\n",
    "\n",
    "        self.covar_module.register_prior(\n",
    "            \"outputscale_prior\",\n",
    "            outputscale_prior,\n",
    "            lambda module: module.outputscale\n",
    "        )\n",
    "\n",
    "        self.likelihood.register_prior(\n",
    "            \"noise_prior\",\n",
    "            noise_prior,\n",
    "            lambda module: module.noise\n",
    "        )\n",
    "\n",
    "        self.likelihood.noise_covar.register_constraint(\"raw_noise\", GreaterThan(1e-5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_XbwbO9ahCz"
   },
   "source": [
    "## 1f. Define Kernel's and Gaussian Process Priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-yCvGBP_NuXg"
   },
   "source": [
    "SVK note: Here, priors on noise and kernel length and scale are our best guesses before the experiment on how the measurement system behaves. Noise is combined effect of how precise are our measurements and how significant are other (uncontrollable) factors that affect the measurements. Kernel lengthscale is basically how rapidly we think the properties can change. Scale is simplest - it is just vertical scale. These guesses are very important - for example, if we think that our measurements are very precise (noise is small) but in reality noise is high, then algorithm will interpret each noise peak as as peak in ground truth (and can go horribly wrong by making kernel length very small). At the same time, if we set kernel length too large, it can never find small modulations in the function. Experiment with these paprameters! Noise in the ground truth vs. noise in the prior, and too big/too small kernel lengths.\n",
    "\n",
    "Priors available to try in [GPyTorch](https://docs.gpytorch.ai/en/latest/priors.html)\n",
    "   - GammaPrior\n",
    "   - HalfCauchyPrior\n",
    "   - LKJCovariancePrior\n",
    "   - MultivariateNormalPrior\n",
    "   - NormalPrior\n",
    "   - LogNormalPrior\n",
    "   - HalfNormalPrior\n",
    "   - SmoothedBoxPrior\n",
    "   - UniformPrior\n",
    "\n",
    "Let's try GammaPrior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Mcv5AEElvNX"
   },
   "outputs": [],
   "source": [
    "### more kernel's to try\n",
    "class RBFKernel(gpytorch.kernels.Kernel):\n",
    "    is_stationary = True\n",
    "\n",
    "    def __init__(self, variance_prior=None, length_prior=None,\n",
    "                 variance_constraint=None, length_constraint=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Register raw parameters\n",
    "        self.register_parameter(\n",
    "            name='raw_lengthscale',  # Changed from raw_length to raw_lengthscale\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name='raw_variance',\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "\n",
    "        # Set constraints\n",
    "        if length_constraint is None:\n",
    "            length_constraint = Positive()\n",
    "        if variance_constraint is None:\n",
    "            variance_constraint = Positive()\n",
    "\n",
    "        self.register_constraint(\"raw_lengthscale\", length_constraint)\n",
    "        self.register_constraint(\"raw_variance\", variance_constraint)\n",
    "\n",
    "        # Set priors if any\n",
    "        if length_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"lengthscale_prior\",  # Changed from length_prior to lengthscale_prior\n",
    "                length_prior,\n",
    "                lambda m: m.lengthscale,  # Changed from length to lengthscale\n",
    "                lambda m, v: m._set_lengthscale(v),  # Changed from _set_length\n",
    "            )\n",
    "        if variance_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"variance_prior\",\n",
    "                variance_prior,\n",
    "                lambda m: m.variance,\n",
    "                lambda m, v: m._set_variance(v),\n",
    "            )\n",
    "\n",
    "    # Lengthscale property\n",
    "    @property\n",
    "    def lengthscale(self):  # Changed from length to lengthscale\n",
    "        return self.raw_lengthscale_constraint.transform(self.raw_lengthscale)\n",
    "\n",
    "    @lengthscale.setter\n",
    "    def lengthscale(self, value):\n",
    "        return self._set_lengthscale(value)\n",
    "\n",
    "    def _set_lengthscale(self, value):  # Changed from _set_length\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_lengthscale)\n",
    "        self.initialize(raw_lengthscale=self.raw_lengthscale_constraint.inverse_transform(value))\n",
    "\n",
    "    # Variance property\n",
    "    @property\n",
    "    def variance(self):\n",
    "        return self.raw_variance_constraint.transform(self.raw_variance)\n",
    "\n",
    "    @variance.setter\n",
    "    def variance(self, value):\n",
    "        return self._set_variance(value)\n",
    "\n",
    "    def _set_variance(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_variance)\n",
    "        self.initialize(raw_variance=self.raw_variance_constraint.inverse_transform(value))\n",
    "\n",
    "    def forward(self, x1, x2, **params):\n",
    "        dist = self.covar_dist(x1, x2, **params)\n",
    "        scaled_dist = dist.div(self.lengthscale)\n",
    "        return self.variance * torch.exp(-0.5 * scaled_dist.pow(2))\n",
    "\n",
    "class Matern52Kernel(gpytorch.kernels.Kernel):\n",
    "    is_stationary = True\n",
    "\n",
    "    def __init__(self, variance_prior=None, length_prior=None,\n",
    "                 variance_constraint=None, length_constraint=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Register raw parameters\n",
    "        self.register_parameter(\n",
    "            name='raw_lengthscale',\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name='raw_variance',\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "\n",
    "        # Set constraints\n",
    "        if length_constraint is None:\n",
    "            length_constraint = Positive()\n",
    "        if variance_constraint is None:\n",
    "            variance_constraint = Positive()\n",
    "\n",
    "        self.register_constraint(\"raw_lengthscale\", length_constraint)\n",
    "        self.register_constraint(\"raw_variance\", variance_constraint)\n",
    "\n",
    "        # Set priors if any\n",
    "        if length_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"lengthscale_prior\",\n",
    "                length_prior,\n",
    "                lambda m: m.lengthscale,\n",
    "                lambda m, v: m._set_lengthscale(v),\n",
    "            )\n",
    "        if variance_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"variance_prior\",\n",
    "                variance_prior,\n",
    "                lambda m: m.variance,\n",
    "                lambda m, v: m._set_variance(v),\n",
    "            )\n",
    "\n",
    "    # Lengthscale property\n",
    "    @property\n",
    "    def lengthscale(self):\n",
    "        return self.raw_lengthscale_constraint.transform(self.raw_lengthscale)\n",
    "\n",
    "    @lengthscale.setter\n",
    "    def lengthscale(self, value):\n",
    "        return self._set_lengthscale(value)\n",
    "\n",
    "    def _set_lengthscale(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_lengthscale)\n",
    "        self.initialize(raw_lengthscale=self.raw_lengthscale_constraint.inverse_transform(value))\n",
    "\n",
    "    # Variance property\n",
    "    @property\n",
    "    def variance(self):\n",
    "        return self.raw_variance_constraint.transform(self.raw_variance)\n",
    "\n",
    "    @variance.setter\n",
    "    def variance(self, value):\n",
    "        return self._set_variance(value)\n",
    "\n",
    "    def _set_variance(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_variance)\n",
    "        self.initialize(raw_variance=self.raw_variance_constraint.inverse_transform(value))\n",
    "\n",
    "    def forward(self, x1, x2, **params):\n",
    "        dist = self.covar_dist(x1, x2, **params)\n",
    "        scaled_dist = dist.div(self.lengthscale)\n",
    "\n",
    "        # Matern 5/2 formula\n",
    "        sqrt_5 = math.sqrt(5.0)\n",
    "        scaled_dist_5_3 = scaled_dist * sqrt_5\n",
    "\n",
    "        return self.variance * (1.0 + scaled_dist_5_3 + (5.0/3.0) * scaled_dist.pow(2)) * \\\n",
    "               torch.exp(-scaled_dist_5_3)\n",
    "\n",
    "class PeriodicKernel(gpytorch.kernels.Kernel):\n",
    "    is_stationary = True\n",
    "\n",
    "    def __init__(self, period_prior=None, length_prior=None, variance_prior=None,\n",
    "                 period_constraint=None, length_constraint=None, variance_constraint=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Register raw parameters\n",
    "        self.register_parameter(\n",
    "            name='raw_period',\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name='raw_lengthscale',\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name='raw_variance',\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "\n",
    "        # Set constraints\n",
    "        if period_constraint is None:\n",
    "            period_constraint = Positive()\n",
    "        if length_constraint is None:\n",
    "            length_constraint = Positive()\n",
    "        if variance_constraint is None:\n",
    "            variance_constraint = Positive()\n",
    "\n",
    "        self.register_constraint(\"raw_period\", period_constraint)\n",
    "        self.register_constraint(\"raw_lengthscale\", length_constraint)\n",
    "        self.register_constraint(\"raw_variance\", variance_constraint)\n",
    "\n",
    "        # Set priors if any\n",
    "        if period_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"period_prior\",\n",
    "                period_prior,\n",
    "                lambda m: m.period,\n",
    "                lambda m, v: m._set_period(v),\n",
    "            )\n",
    "        if length_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"lengthscale_prior\",\n",
    "                length_prior,\n",
    "                lambda m: m.lengthscale,\n",
    "                lambda m, v: m._set_lengthscale(v),\n",
    "            )\n",
    "        if variance_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"variance_prior\",\n",
    "                variance_prior,\n",
    "                lambda m: m.variance,\n",
    "                lambda m, v: m._set_variance(v),\n",
    "            )\n",
    "\n",
    "    # Period property\n",
    "    @property\n",
    "    def period(self):\n",
    "        return self.raw_period_constraint.transform(self.raw_period)\n",
    "\n",
    "    @period.setter\n",
    "    def period(self, value):\n",
    "        return self._set_period(value)\n",
    "\n",
    "    def _set_period(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_period)\n",
    "        self.initialize(raw_period=self.raw_period_constraint.inverse_transform(value))\n",
    "\n",
    "    # Lengthscale property\n",
    "    @property\n",
    "    def lengthscale(self):\n",
    "        return self.raw_lengthscale_constraint.transform(self.raw_lengthscale)\n",
    "\n",
    "    @lengthscale.setter\n",
    "    def lengthscale(self, value):\n",
    "        return self._set_lengthscale(value)\n",
    "\n",
    "    def _set_lengthscale(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_lengthscale)\n",
    "        self.initialize(raw_lengthscale=self.raw_lengthscale_constraint.inverse_transform(value))\n",
    "\n",
    "    # Variance property\n",
    "    @property\n",
    "    def variance(self):\n",
    "        return self.raw_variance_constraint.transform(self.raw_variance)\n",
    "\n",
    "    @variance.setter\n",
    "    def variance(self, value):\n",
    "        return self._set_variance(value)\n",
    "\n",
    "    def _set_variance(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_variance)\n",
    "        self.initialize(raw_variance=self.raw_variance_constraint.inverse_transform(value))\n",
    "\n",
    "    def forward(self, x1, x2, **params):\n",
    "        dist = self.covar_dist(x1, x2, **params)\n",
    "        # Periodic kernel formula: k(x,x') = σ² * exp(-2 * sin²(π|x-x'|/p) / ℓ²)\n",
    "        scaled_sin = torch.sin(math.pi * dist / self.period)\n",
    "        exp_term = -2 * (scaled_sin ** 2) / (self.lengthscale ** 2)\n",
    "        return self.variance * torch.exp(exp_term)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yT2GFO89lvNX"
   },
   "outputs": [],
   "source": [
    "## define priors\n",
    "from gpytorch.priors import GammaPrior, NormalPrior\n",
    "from gpytorch.priors import UniformPrior, LogNormalPrior, HalfNormalPrior, NormalPrior\n",
    "from gpytorch.constraints import Interval\n",
    "\n",
    "lengthscale_prior = UniformPrior(0.10, 0.5)# length scale in RBF kernel\n",
    "outputscale_prior = LogNormalPrior(0, 1)# Variance in RBF kernel\n",
    "# noise_prior = HalfNormalPrior(0.01, 1)\n",
    "noise_prior = NormalPrior(0, 0.1)\n",
    "length_constraint = Interval(0.10, 0.5)  # Matching constraint to lengthscale_prior distribution support , kernel length often need constraints (e.g., positive values) -\n",
    "\n",
    "# kernel = RBFKernel(length_prior=lengthscale_prior,\n",
    "#                    length_constraint=length_constraint\n",
    "#                    )\n",
    "kernel = Matern52Kernel(length_prior=lengthscale_prior,\n",
    "                   length_constraint=length_constraint\n",
    "                   )\n",
    "# kernel = PeriodicKernel(length_prior=lengthscale_prior,\n",
    "#                    length_constraint=length_constraint\n",
    "#                    )\n",
    "\n",
    "## more priors: GammaPrior, HalfCauchyPrior, LKJCovariancePrior, MultivariateNormalPrior, NormalPrior, SmoothedBoxPrior, UniformPrior, LogNormalPrior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 1013,
     "status": "ok",
     "timestamp": 1736877719670,
     "user": {
      "displayName": "Utkarsh Pratiush",
      "userId": "14303792046592850693"
     },
     "user_tz": -330
    },
    "id": "88-aiZJQlvNX",
    "outputId": "129703ca-dcc0-4550-f777-f3d3e3cbe61f"
   },
   "outputs": [],
   "source": [
    "# Generate samples\n",
    "num_samples = 10000\n",
    "samples = noise_prior.sample(torch.Size([num_samples]))\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Histogram of samples\n",
    "plt.hist(samples.numpy(), bins=50, density=True, alpha=0.6, color='blue', label='Samples')\n",
    "\n",
    "# Generate points for the PDF\n",
    "x = np.linspace(0, 1, 1000)\n",
    "pdf = noise_prior.log_prob(torch.tensor(x)).exp()\n",
    "plt.plot(x, pdf, 'r-', lw=2, label='PDF')\n",
    "\n",
    "plt.title('Noise prior')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6qw6rvVlvNX"
   },
   "source": [
    "## 1g. Active-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nMPEb0yMlvNY"
   },
   "outputs": [],
   "source": [
    "def plot_step(model, X, y, candidate, acq_func, discrete_points, step):\n",
    "    # Create evaluation points (use discrete points for visualization)\n",
    "    x_plot = discrete_points[:, 0]\n",
    "\n",
    "    # Get posterior\n",
    "    with torch.no_grad():\n",
    "        posterior = model.posterior(discrete_points)\n",
    "        mean = posterior.mean.squeeze()\n",
    "        std = posterior.variance.sqrt().squeeze()\n",
    "\n",
    "\n",
    "    # Get acquisition values\n",
    "    with torch.no_grad():\n",
    "        acq_values = acq_func(discrete_points.unsqueeze(1)).squeeze()\n",
    "\n",
    "    # Ground truth\n",
    "    y_true = func(x_plot.detach().numpy())\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot posterior\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x_plot.detach().numpy(), y_true, 'k--', label='True function')\n",
    "    plt.plot(x_plot.detach().numpy(), mean.detach().numpy(), 'b-', label='Posterior mean')\n",
    "    plt.fill_between(x_plot.detach().numpy(),\n",
    "                    (mean - 2*std).detach().numpy(),\n",
    "                    (mean + 2*std).detach().numpy(),\n",
    "                    alpha=0.3, color='b')\n",
    "    plt.plot(X.detach().numpy().squeeze(), y.detach().numpy(), 'r.', markersize=10, label='Observations')\n",
    "    plt.plot(candidate.detach().numpy().squeeze(), func(candidate.detach().numpy().squeeze()), 'g*', markersize=15, label='Next point')\n",
    "    plt.legend()\n",
    "    plt.title(f'Step {step}: Posterior and Observations')\n",
    "\n",
    "    # Plot acquisition function\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x_plot.detach().numpy(), acq_values.detach().numpy(), 'r-', label='Acquisition function')\n",
    "    plt.plot(candidate.detach().numpy().squeeze(),\n",
    "            acq_func(candidate.unsqueeze(1)).detach().numpy(),\n",
    "            'g*', markersize=15, label='Next point')\n",
    "    plt.legend()\n",
    "    plt.title('Acquisition Function')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(f\"{out_dir}/{step}.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y22QnnD7lvNY"
   },
   "outputs": [],
   "source": [
    "def print_detailed_model_parameters(model):\n",
    "    \"\"\"\n",
    "    Print detailed statistics about the GP model parameters\n",
    "    \"\"\"\n",
    "    # Lengthscale\n",
    "    lengthscale = model.covar_module.base_kernel.lengthscale\n",
    "    print(\"\\nLengthscale:\")\n",
    "    print(f\"  Value: {lengthscale.item():.3f}\")\n",
    "    if hasattr(model.covar_module.base_kernel, 'lengthscale_prior'):\n",
    "        prior = model.covar_module.base_kernel.lengthscale_prior\n",
    "        print(f\"  Prior mean: {prior.mean.item():.3f}\")\n",
    "        print(f\"  Prior std: {prior.stddev.item():.3f}\")\n",
    "\n",
    "    # Outputscale\n",
    "    outputscale = model.covar_module.outputscale\n",
    "    print(\"\\nOutputscale:\")\n",
    "    print(f\"  Value: {outputscale.item():.3f}\")\n",
    "    if hasattr(model.covar_module, 'outputscale_prior'):\n",
    "        prior = model.covar_module.outputscale_prior\n",
    "        print(f\"  Prior mean: {prior.mean.item():.3f}\")\n",
    "        print(f\"  Prior std: {prior.stddev.item():.3f}\")\n",
    "\n",
    "    # Noise\n",
    "    noise = model.likelihood.noise\n",
    "    print(\"\\nNoise:\")\n",
    "    print(f\"  Value: {noise.item():.3f}\")\n",
    "    if hasattr(model.likelihood, 'noise_prior'):\n",
    "        prior = model.likelihood.noise_prior\n",
    "        print(f\"  Prior mean: {prior.mean.item():.3f}\")\n",
    "        print(f\"  Prior std: {prior.stddev.item():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 11198,
     "status": "ok",
     "timestamp": 1736877738490,
     "user": {
      "displayName": "Utkarsh Pratiush",
      "userId": "14303792046592850693"
     },
     "user_tz": -330
    },
    "id": "rGNF7tRQlvNY",
    "outputId": "c9626418-01ce-4c1b-abe2-07c8f6d77bab"
   },
   "outputs": [],
   "source": [
    "# Create discrete grid\n",
    "x_points = torch.linspace(-2, 2, 50, dtype=torch.double)\n",
    "discrete_points = x_points.unsqueeze(-1)\n",
    "\n",
    "# Initial training data\n",
    "n_train = 2\n",
    "train_indices = torch.randperm(len(discrete_points))[:n_train]\n",
    "X = discrete_points[train_indices]\n",
    "# y = torch.tensor(measure(X), dtype=torch.double)\n",
    "y = torch.tensor(measure(X, noise=0), dtype=torch.double)\n",
    "\n",
    "\n",
    "n_iterations = 10\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.acquisition import ExpectedImprovement\n",
    "from botorch.optim import optimize_acqf_discrete\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.acquisition import UpperConfidenceBound\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "for step in range(n_iterations):\n",
    "    # Fit GP\n",
    "    model = CustomGP(X, y, kernel, lengthscale_prior, outputscale_prior, noise_prior)\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    fit_gpytorch_mll(mll)\n",
    "    print_detailed_model_parameters(model)\n",
    "\n",
    "\n",
    "    # Define acquisition function\n",
    "    # EI = ExpectedImprovement(model=model, best_f=y.min())\n",
    "    # UCB = UpperConfidenceBound(model=model, beta=0)  # beta controls exploration vs exploitation\n",
    "    # Define acquisition function\n",
    "    acq_func = UpperConfidenceBound(model=model, beta = 1e6 ) #--> higher beta maximum uncertanity\n",
    "    # Get remaining points (exclude training points)\n",
    "    mask = torch.ones(len(discrete_points), dtype=torch.bool)\n",
    "    mask[train_indices] = False\n",
    "    available_points = discrete_points[mask]\n",
    "\n",
    "    # Optimize acquisition function discretely\n",
    "    candidate, acq_value = optimize_acqf_discrete(\n",
    "        acq_function=acq_func,\n",
    "        q=1,\n",
    "        choices=available_points,\n",
    "        unique=True,\n",
    "    )\n",
    "\n",
    "    # Plot\n",
    "    plot_step(model, X, y, candidate, acq_func, discrete_points, step + 1)\n",
    "\n",
    "    # Update data\n",
    "    X = torch.cat([X, candidate])\n",
    "    y_new = torch.tensor([[measure(candidate.item(), noise=0)]], dtype=torch.double)\n",
    "\n",
    "    y = torch.cat([y, y_new])\n",
    "\n",
    "    # Update training indices\n",
    "    new_idx = torch.where((discrete_points == candidate).all(dim=1))[0]\n",
    "    train_indices = torch.cat([train_indices, new_idx])\n",
    "\n",
    "print(\"\\nOptimization completed!\")\n",
    "print(f\"Best observed value: {y.min().detach().item():.3f}\")\n",
    "print(f\"At location: {X[y.argmin()].detach().item():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0579Zy7q7rT0"
   },
   "source": [
    "# 2.Mean Functions - Structured GP\n",
    "- Rewritten in Gpytorch and Botorch by [Utkarsh Pratiush](https://github.com/utkarshp1161). [Originally in Gpax](https://github.com/SergeiVKalinin/ACerS_AE_2024/blob/main/10_GPax_sGP_AE.ipynb) by [Maxim Ziatdinov](https://github.com/ziatdinovmax) and [SVK](https://github.com/SergeiVKalinin)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8E3KjtNX9Sz6"
   },
   "source": [
    "## 2a. Mean function - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfVZ1pk17wHY"
   },
   "source": [
    "### 2a(i).Define mean function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 908,
     "status": "ok",
     "timestamp": 1736877677840,
     "user": {
      "displayName": "Utkarsh Pratiush",
      "userId": "14303792046592850693"
     },
     "user_tz": -330
    },
    "id": "Wn4Dfc977ynC",
    "outputId": "6577a52d-b8f1-4c86-ca1f-30e5a3cb86e6"
   },
   "outputs": [],
   "source": [
    "class CustomMean(gpytorch.means.Mean):\n",
    "    def __init__(self, batch_shape=torch.Size()):\n",
    "        super().__init__()\n",
    "\n",
    "        # Register raw parameters (will be transformed to ensure positivity)\n",
    "        self.register_parameter(\n",
    "            name=\"raw_amplitude\",\n",
    "            parameter=torch.nn.Parameter(torch.tensor(3.0))  # log(20) ≈ 3\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name=\"raw_scale\",\n",
    "            parameter=torch.nn.Parameter(torch.tensor(-1.6))  # log(0.2) ≈ -1.6\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name=\"raw_offset\",\n",
    "            parameter=torch.nn.Parameter(torch.tensor(3.0))  # log(20) ≈ 3\n",
    "        )\n",
    "\n",
    "        # Register constraints\n",
    "        self.register_constraint(\"raw_amplitude\", Positive())\n",
    "        self.register_constraint(\"raw_scale\", Positive())\n",
    "        self.register_constraint(\"raw_offset\", Positive())\n",
    "\n",
    "        # Register priors\n",
    "        self.register_prior(\n",
    "            \"amplitude_prior\",\n",
    "            LogNormalPrior(3.0, 0.5),  # mean=log(20), std=0.5\n",
    "            lambda module: module.amplitude,\n",
    "            lambda module, value: module._set_amplitude(value)\n",
    "        )\n",
    "        self.register_prior(\n",
    "            \"scale_prior\",\n",
    "            LogNormalPrior(-1.6, 0.5),  # mean=log(0.2), std=0.5\n",
    "            lambda module: module.scale,\n",
    "            lambda module, value: module._set_scale(value)\n",
    "        )\n",
    "        self.register_prior(\n",
    "            \"offset_prior\",\n",
    "            LogNormalPrior(3.0, 0.5),  # mean=log(20), std=0.5\n",
    "            lambda module: module.offset,\n",
    "            lambda module, value: module._set_offset(value)\n",
    "        )\n",
    "\n",
    "    # Properties to transform raw parameters\n",
    "    @property\n",
    "    def amplitude(self):\n",
    "        return self.raw_amplitude_constraint.transform(self.raw_amplitude)\n",
    "\n",
    "    @property\n",
    "    def scale(self):\n",
    "        return self.raw_scale_constraint.transform(self.raw_scale)\n",
    "\n",
    "    @property\n",
    "    def offset(self):\n",
    "        return self.raw_offset_constraint.transform(self.raw_offset)\n",
    "\n",
    "    # Setters for parameters\n",
    "    def _set_amplitude(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.tensor(value)\n",
    "        self.initialize(raw_amplitude=self.raw_amplitude_constraint.inverse_transform(value))\n",
    "\n",
    "    def _set_scale(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.tensor(value)\n",
    "        self.initialize(raw_scale=self.raw_scale_constraint.inverse_transform(value))\n",
    "\n",
    "    def _set_offset(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.tensor(value)\n",
    "        self.initialize(raw_offset=self.raw_offset_constraint.inverse_transform(value))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.ndimension() == 1:\n",
    "            x = x.unsqueeze(-1)\n",
    "\n",
    "        # Use transformed parameters in the computation\n",
    "        term1 = -self.amplitude * torch.exp(-self.scale * torch.sqrt(torch.sum(x**2, dim=-1)))\n",
    "        return term1 + self.offset\n",
    "\n",
    "\n",
    "def plot_mean_function(mean_module, x_range=(-2, 2), n_points=100):\n",
    "    \"\"\"\n",
    "    Plot the mean function over a specified range.\n",
    "\n",
    "    Args:\n",
    "        mean_module: The CustomMean instance\n",
    "        x_range: Tuple of (min_x, max_x)\n",
    "        n_points: Number of points to evaluate\n",
    "    \"\"\"\n",
    "    # Create evaluation points\n",
    "    x = np.linspace(x_range[0], x_range[1], n_points)\n",
    "    x_tensor = torch.tensor(x, dtype=torch.float64).reshape(-1, 1)\n",
    "\n",
    "    # Evaluate mean function\n",
    "    with torch.no_grad():\n",
    "        mean_values = mean_module(x_tensor).numpy()\n",
    "\n",
    "    # Create figure\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot mean function\n",
    "    plt.plot(x, mean_values, 'b-', label='Mean Function')\n",
    "\n",
    "    # Plot true function for comparison\n",
    "    true_y = np.array([func(xi) for xi in x])\n",
    "    plt.plot(x, true_y, 'r--', label='True Function')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title('Mean Function vs True Function')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Show parameter values\n",
    "    param_text = f'Parameters:\\nAmplitude: {mean_module.amplitude.item():.3f}\\n'\n",
    "    param_text += f'Scale: {mean_module.scale.item():.3f}\\n'\n",
    "    param_text += f'Offset: {mean_module.offset.item():.3f}'\n",
    "\n",
    "    plt.text(0.02, 0.98, param_text,\n",
    "             transform=plt.gca().transAxes,\n",
    "             verticalalignment='top',\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Create and plot mean function\n",
    "mean_module = CustomMean()\n",
    "plot_mean_function(mean_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Do_Yvt-n77wE"
   },
   "source": [
    "### 2b(ii). Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p4cQ6k7l72Qv"
   },
   "outputs": [],
   "source": [
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.transforms import Standardize, Normalize\n",
    "# from gpytorch.kernels import RBFKernel, ScaleKernel\n",
    "from gpytorch.kernels import  ScaleKernel\n",
    "\n",
    "from gpytorch.constraints import GreaterThan\n",
    "\n",
    "class CustomGP(SingleTaskGP):\n",
    "    def __init__(self, train_X, train_Y, kernel, lengthscale_prior, outputscale_prior, noise_prior):\n",
    "        super().__init__(\n",
    "            train_X,\n",
    "            train_Y,\n",
    "            input_transform=Normalize(d=1),\n",
    "            outcome_transform=Standardize(m=1)\n",
    "        )\n",
    "\n",
    "        # Replace default mean module with custom mean\n",
    "        self.mean_module = CustomMean()\n",
    "        # self.mean_module = AckleyMean()\n",
    "\n",
    "        # Replace default kernel with custom kernel\n",
    "        self.covar_module = ScaleKernel(kernel)\n",
    "\n",
    "        # Register priors\n",
    "        self.covar_module.base_kernel.register_prior(\n",
    "            \"lengthscale_prior\",\n",
    "            lengthscale_prior,\n",
    "            lambda module: module.lengthscale,\n",
    "            lambda module, value: module._set_lengthscale(value)\n",
    "        )\n",
    "\n",
    "        self.covar_module.register_prior(\n",
    "            \"outputscale_prior\",\n",
    "            outputscale_prior,\n",
    "            lambda module: module.outputscale\n",
    "        )\n",
    "\n",
    "        self.likelihood.register_prior(\n",
    "            \"noise_prior\",\n",
    "            noise_prior,\n",
    "            lambda module: module.noise\n",
    "        )\n",
    "\n",
    "        self.likelihood.noise_covar.register_constraint(\"raw_noise\", GreaterThan(1e-5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "smfuomEU8CYm"
   },
   "source": [
    "### 2c(iii). Register kerne-priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 549,
     "status": "ok",
     "timestamp": 1736877684163,
     "user": {
      "displayName": "Utkarsh Pratiush",
      "userId": "14303792046592850693"
     },
     "user_tz": -330
    },
    "id": "sjzJyOoC8Bj0",
    "outputId": "688770b7-11d3-45d3-fe4a-24b36b4954a0"
   },
   "outputs": [],
   "source": [
    "### more kernel's to try\n",
    "class RBFKernel(gpytorch.kernels.Kernel):\n",
    "    is_stationary = True\n",
    "\n",
    "    def __init__(self, variance_prior=None, length_prior=None,\n",
    "                 variance_constraint=None, length_constraint=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Register raw parameters\n",
    "        self.register_parameter(\n",
    "            name='raw_lengthscale',  # Changed from raw_length to raw_lengthscale\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name='raw_variance',\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "\n",
    "        # Set constraints\n",
    "        if length_constraint is None:\n",
    "            length_constraint = Positive()\n",
    "        if variance_constraint is None:\n",
    "            variance_constraint = Positive()\n",
    "\n",
    "        self.register_constraint(\"raw_lengthscale\", length_constraint)\n",
    "        self.register_constraint(\"raw_variance\", variance_constraint)\n",
    "\n",
    "        # Set priors if any\n",
    "        if length_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"lengthscale_prior\",  # Changed from length_prior to lengthscale_prior\n",
    "                length_prior,\n",
    "                lambda m: m.lengthscale,  # Changed from length to lengthscale\n",
    "                lambda m, v: m._set_lengthscale(v),  # Changed from _set_length\n",
    "            )\n",
    "        if variance_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"variance_prior\",\n",
    "                variance_prior,\n",
    "                lambda m: m.variance,\n",
    "                lambda m, v: m._set_variance(v),\n",
    "            )\n",
    "\n",
    "    # Lengthscale property\n",
    "    @property\n",
    "    def lengthscale(self):  # Changed from length to lengthscale\n",
    "        return self.raw_lengthscale_constraint.transform(self.raw_lengthscale)\n",
    "\n",
    "    @lengthscale.setter\n",
    "    def lengthscale(self, value):\n",
    "        return self._set_lengthscale(value)\n",
    "\n",
    "    def _set_lengthscale(self, value):  # Changed from _set_length\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_lengthscale)\n",
    "        self.initialize(raw_lengthscale=self.raw_lengthscale_constraint.inverse_transform(value))\n",
    "\n",
    "    # Variance property\n",
    "    @property\n",
    "    def variance(self):\n",
    "        return self.raw_variance_constraint.transform(self.raw_variance)\n",
    "\n",
    "    @variance.setter\n",
    "    def variance(self, value):\n",
    "        return self._set_variance(value)\n",
    "\n",
    "    def _set_variance(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_variance)\n",
    "        self.initialize(raw_variance=self.raw_variance_constraint.inverse_transform(value))\n",
    "\n",
    "    def forward(self, x1, x2, **params):\n",
    "        dist = self.covar_dist(x1, x2, **params)\n",
    "        scaled_dist = dist.div(self.lengthscale)\n",
    "        return self.variance * torch.exp(-0.5 * scaled_dist.pow(2))\n",
    "\n",
    "class Matern52Kernel(gpytorch.kernels.Kernel):\n",
    "    is_stationary = True\n",
    "\n",
    "    def __init__(self, variance_prior=None, length_prior=None,\n",
    "                 variance_constraint=None, length_constraint=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Register raw parameters\n",
    "        self.register_parameter(\n",
    "            name='raw_lengthscale',\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name='raw_variance',\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "\n",
    "        # Set constraints\n",
    "        if length_constraint is None:\n",
    "            length_constraint = Positive()\n",
    "        if variance_constraint is None:\n",
    "            variance_constraint = Positive()\n",
    "\n",
    "        self.register_constraint(\"raw_lengthscale\", length_constraint)\n",
    "        self.register_constraint(\"raw_variance\", variance_constraint)\n",
    "\n",
    "        # Set priors if any\n",
    "        if length_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"lengthscale_prior\",\n",
    "                length_prior,\n",
    "                lambda m: m.lengthscale,\n",
    "                lambda m, v: m._set_lengthscale(v),\n",
    "            )\n",
    "        if variance_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"variance_prior\",\n",
    "                variance_prior,\n",
    "                lambda m: m.variance,\n",
    "                lambda m, v: m._set_variance(v),\n",
    "            )\n",
    "\n",
    "    # Lengthscale property\n",
    "    @property\n",
    "    def lengthscale(self):\n",
    "        return self.raw_lengthscale_constraint.transform(self.raw_lengthscale)\n",
    "\n",
    "    @lengthscale.setter\n",
    "    def lengthscale(self, value):\n",
    "        return self._set_lengthscale(value)\n",
    "\n",
    "    def _set_lengthscale(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_lengthscale)\n",
    "        self.initialize(raw_lengthscale=self.raw_lengthscale_constraint.inverse_transform(value))\n",
    "\n",
    "    # Variance property\n",
    "    @property\n",
    "    def variance(self):\n",
    "        return self.raw_variance_constraint.transform(self.raw_variance)\n",
    "\n",
    "    @variance.setter\n",
    "    def variance(self, value):\n",
    "        return self._set_variance(value)\n",
    "\n",
    "    def _set_variance(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_variance)\n",
    "        self.initialize(raw_variance=self.raw_variance_constraint.inverse_transform(value))\n",
    "\n",
    "    def forward(self, x1, x2, **params):\n",
    "        dist = self.covar_dist(x1, x2, **params)\n",
    "        scaled_dist = dist.div(self.lengthscale)\n",
    "\n",
    "        # Matern 5/2 formula\n",
    "        sqrt_5 = math.sqrt(5.0)\n",
    "        scaled_dist_5_3 = scaled_dist * sqrt_5\n",
    "\n",
    "        return self.variance * (1.0 + scaled_dist_5_3 + (5.0/3.0) * scaled_dist.pow(2)) * \\\n",
    "               torch.exp(-scaled_dist_5_3)\n",
    "\n",
    "class PeriodicKernel(gpytorch.kernels.Kernel):\n",
    "    is_stationary = True\n",
    "\n",
    "    def __init__(self, period_prior=None, length_prior=None, variance_prior=None,\n",
    "                 period_constraint=None, length_constraint=None, variance_constraint=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Register raw parameters\n",
    "        self.register_parameter(\n",
    "            name='raw_period',\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name='raw_lengthscale',\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name='raw_variance',\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "\n",
    "        # Set constraints\n",
    "        if period_constraint is None:\n",
    "            period_constraint = Positive()\n",
    "        if length_constraint is None:\n",
    "            length_constraint = Positive()\n",
    "        if variance_constraint is None:\n",
    "            variance_constraint = Positive()\n",
    "\n",
    "        self.register_constraint(\"raw_period\", period_constraint)\n",
    "        self.register_constraint(\"raw_lengthscale\", length_constraint)\n",
    "        self.register_constraint(\"raw_variance\", variance_constraint)\n",
    "\n",
    "        # Set priors if any\n",
    "        if period_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"period_prior\",\n",
    "                period_prior,\n",
    "                lambda m: m.period,\n",
    "                lambda m, v: m._set_period(v),\n",
    "            )\n",
    "        if length_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"lengthscale_prior\",\n",
    "                length_prior,\n",
    "                lambda m: m.lengthscale,\n",
    "                lambda m, v: m._set_lengthscale(v),\n",
    "            )\n",
    "        if variance_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"variance_prior\",\n",
    "                variance_prior,\n",
    "                lambda m: m.variance,\n",
    "                lambda m, v: m._set_variance(v),\n",
    "            )\n",
    "\n",
    "    # Period property\n",
    "    @property\n",
    "    def period(self):\n",
    "        return self.raw_period_constraint.transform(self.raw_period)\n",
    "\n",
    "    @period.setter\n",
    "    def period(self, value):\n",
    "        return self._set_period(value)\n",
    "\n",
    "    def _set_period(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_period)\n",
    "        self.initialize(raw_period=self.raw_period_constraint.inverse_transform(value))\n",
    "\n",
    "    # Lengthscale property\n",
    "    @property\n",
    "    def lengthscale(self):\n",
    "        return self.raw_lengthscale_constraint.transform(self.raw_lengthscale)\n",
    "\n",
    "    @lengthscale.setter\n",
    "    def lengthscale(self, value):\n",
    "        return self._set_lengthscale(value)\n",
    "\n",
    "    def _set_lengthscale(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_lengthscale)\n",
    "        self.initialize(raw_lengthscale=self.raw_lengthscale_constraint.inverse_transform(value))\n",
    "\n",
    "    # Variance property\n",
    "    @property\n",
    "    def variance(self):\n",
    "        return self.raw_variance_constraint.transform(self.raw_variance)\n",
    "\n",
    "    @variance.setter\n",
    "    def variance(self, value):\n",
    "        return self._set_variance(value)\n",
    "\n",
    "    def _set_variance(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_variance)\n",
    "        self.initialize(raw_variance=self.raw_variance_constraint.inverse_transform(value))\n",
    "\n",
    "    def forward(self, x1, x2, **params):\n",
    "        dist = self.covar_dist(x1, x2, **params)\n",
    "        # Periodic kernel formula: k(x,x') = σ² * exp(-2 * sin²(π|x-x'|/p) / ℓ²)\n",
    "        scaled_sin = torch.sin(math.pi * dist / self.period)\n",
    "        exp_term = -2 * (scaled_sin ** 2) / (self.lengthscale ** 2)\n",
    "        return self.variance * torch.exp(exp_term)\n",
    "\n",
    "\n",
    "\n",
    "## define priors\n",
    "from gpytorch.priors import GammaPrior, NormalPrior\n",
    "from gpytorch.priors import UniformPrior, LogNormalPrior, HalfNormalPrior, NormalPrior\n",
    "from gpytorch.constraints import Interval\n",
    "\n",
    "lengthscale_prior = UniformPrior(0.10, 0.5)# length scale in RBF kernel\n",
    "outputscale_prior = LogNormalPrior(0, 1)# Variance in RBF kernel\n",
    "# noise_prior = HalfNormalPrior(0.01, 1)\n",
    "noise_prior = NormalPrior(0, 0.1)\n",
    "length_constraint = Interval(0.10, 0.5)  # Matching constraint to lengthscale_prior distribution support , kernel length often need constraints (e.g., positive values) -\n",
    "\n",
    "# kernel = RBFKernel(length_prior=lengthscale_prior,\n",
    "#                    length_constraint=length_constraint\n",
    "#                    )\n",
    "kernel = Matern52Kernel(length_prior=lengthscale_prior,\n",
    "                   length_constraint=length_constraint\n",
    "                   )\n",
    "# kernel = PeriodicKernel(length_prior=lengthscale_prior,\n",
    "#                    length_constraint=length_constraint\n",
    "#                    )\n",
    "\n",
    "## more priors: GammaPrior, HalfCauchyPrior, LKJCovariancePrior, MultivariateNormalPrior, NormalPrior, SmoothedBoxPrior, UniformPrior, LogNormalPrior\n",
    "\n",
    "# Generate samples\n",
    "num_samples = 10000\n",
    "samples = noise_prior.sample(torch.Size([num_samples]))\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Histogram of samples\n",
    "plt.hist(samples.numpy(), bins=50, density=True, alpha=0.6, color='blue', label='Samples')\n",
    "\n",
    "# Generate points for the PDF\n",
    "x = np.linspace(0, 1, 1000)\n",
    "pdf = noise_prior.log_prob(torch.tensor(x)).exp()\n",
    "plt.plot(x, pdf, 'r-', lw=2, label='PDF')\n",
    "\n",
    "plt.title('Noise prior')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3PD3a7g8plI"
   },
   "source": [
    "### 2d(iv). Active learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 13191,
     "status": "ok",
     "timestamp": 1736877699477,
     "user": {
      "displayName": "Utkarsh Pratiush",
      "userId": "14303792046592850693"
     },
     "user_tz": -330
    },
    "id": "zSMLD2j28L05",
    "outputId": "e74d56ad-743c-4b87-b898-c00bf9f31274"
   },
   "outputs": [],
   "source": [
    "# Create discrete grid\n",
    "x_points = torch.linspace(-2, 2, 50, dtype=torch.double)\n",
    "discrete_points = x_points.unsqueeze(-1)\n",
    "\n",
    "# Initial training data\n",
    "n_train = 2\n",
    "train_indices = torch.randperm(len(discrete_points))[:n_train]\n",
    "X = discrete_points[train_indices]\n",
    "# y = torch.tensor(measure(X), dtype=torch.double)\n",
    "y = torch.tensor(measure(X, noise=0), dtype=torch.double)\n",
    "\n",
    "\n",
    "n_iterations = 10\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.acquisition import ExpectedImprovement\n",
    "from botorch.optim import optimize_acqf_discrete\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.acquisition import UpperConfidenceBound\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "for step in range(n_iterations):\n",
    "    # Fit GP\n",
    "    model = CustomGP(X, y, kernel, lengthscale_prior, outputscale_prior, noise_prior)\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    fit_gpytorch_mll(mll)\n",
    "    print_detailed_model_parameters(model)\n",
    "\n",
    "\n",
    "    # Define acquisition function\n",
    "    # EI = ExpectedImprovement(model=model, best_f=y.min())\n",
    "    # UCB = UpperConfidenceBound(model=model, beta=0)  # beta controls exploration vs exploitation\n",
    "    # Define acquisition function\n",
    "    acq_func = UpperConfidenceBound(model=model, beta = 1e6 ) #--> higher beta maximum uncertanity\n",
    "    # Get remaining points (exclude training points)\n",
    "    mask = torch.ones(len(discrete_points), dtype=torch.bool)\n",
    "    mask[train_indices] = False\n",
    "    available_points = discrete_points[mask]\n",
    "\n",
    "    # Optimize acquisition function discretely\n",
    "    candidate, acq_value = optimize_acqf_discrete(\n",
    "        acq_function=acq_func,\n",
    "        q=1,\n",
    "        choices=available_points,\n",
    "        unique=True,\n",
    "    )\n",
    "\n",
    "    # Plot\n",
    "    plot_step(model, X, y, candidate, acq_func, discrete_points, step + 1)\n",
    "\n",
    "    # Update data\n",
    "    X = torch.cat([X, candidate])\n",
    "    y_new = torch.tensor([[measure(candidate.item(), noise=0)]], dtype=torch.double)\n",
    "\n",
    "    y = torch.cat([y, y_new])\n",
    "\n",
    "    # Update training indices\n",
    "    new_idx = torch.where((discrete_points == candidate).all(dim=1))[0]\n",
    "    train_indices = torch.cat([train_indices, new_idx])\n",
    "\n",
    "print(\"\\nOptimization completed!\")\n",
    "print(f\"Best observed value: {y.min().detach().item():.3f}\")\n",
    "print(f\"At location: {X[y.argmin()].detach().item():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59VSmpyD9z82"
   },
   "source": [
    "## 2b. Mean function - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XaUOqBIy9z83"
   },
   "source": [
    "### 2b(i). Define mean function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "executionInfo": {
     "elapsed": 734,
     "status": "ok",
     "timestamp": 1736877627674,
     "user": {
      "displayName": "Utkarsh Pratiush",
      "userId": "14303792046592850693"
     },
     "user_tz": -330
    },
    "id": "kX1dHkUI9z83",
    "outputId": "e9a7f559-91f3-48c5-c688-472370465add"
   },
   "outputs": [],
   "source": [
    "class AckleyMean(gpytorch.means.Mean):\n",
    "    def __init__(self, batch_shape=torch.Size()):\n",
    "        super().__init__()\n",
    "\n",
    "        # Register raw parameters with reasonable initial values\n",
    "        self.register_parameter(\n",
    "            name=\"raw_amplitude1\",\n",
    "            parameter=torch.nn.Parameter(torch.tensor(3.0))  # log(20)\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name=\"raw_amplitude2\",\n",
    "            parameter=torch.nn.Parameter(torch.tensor(0.0))  # log(1)\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name=\"raw_scale1\",\n",
    "            parameter=torch.nn.Parameter(torch.tensor(-1.6))  # log(0.2)\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name=\"raw_scale2\",\n",
    "            parameter=torch.nn.Parameter(torch.tensor(0.0))  # log(1)\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name=\"raw_offset\",\n",
    "            parameter=torch.nn.Parameter(torch.tensor(3.0))  # log(20)\n",
    "        )\n",
    "\n",
    "        # Register constraints for all parameters\n",
    "        for param in [\"raw_amplitude1\", \"raw_amplitude2\", \"raw_scale1\", \"raw_scale2\", \"raw_offset\"]:\n",
    "            self.register_constraint(param, Positive())\n",
    "\n",
    "        # Register priors\n",
    "        self.register_prior(\n",
    "            \"amplitude1_prior\",\n",
    "            LogNormalPrior(3.0, 0.5),\n",
    "            lambda module: module.amplitude1,\n",
    "            lambda module, value: module._set_amplitude1(value)\n",
    "        )\n",
    "        self.register_prior(\n",
    "            \"amplitude2_prior\",\n",
    "            LogNormalPrior(0.0, 0.5),\n",
    "            lambda module: module.amplitude2,\n",
    "            lambda module, value: module._set_amplitude2(value)\n",
    "        )\n",
    "        self.register_prior(\n",
    "            \"scale1_prior\",\n",
    "            LogNormalPrior(-1.6, 0.5),\n",
    "            lambda module: module.scale1,\n",
    "            lambda module, value: module._set_scale1(value)\n",
    "        )\n",
    "        self.register_prior(\n",
    "            \"scale2_prior\",\n",
    "            LogNormalPrior(0.0, 0.5),\n",
    "            lambda module: module.scale2,\n",
    "            lambda module, value: module._set_scale2(value)\n",
    "        )\n",
    "        self.register_prior(\n",
    "            \"offset_prior\",\n",
    "            LogNormalPrior(3.0, 0.5),\n",
    "            lambda module: module.offset,\n",
    "            lambda module, value: module._set_offset(value)\n",
    "        )\n",
    "\n",
    "    # Properties for transformed parameters\n",
    "    @property\n",
    "    def amplitude1(self):\n",
    "        return self.raw_amplitude1_constraint.transform(self.raw_amplitude1)\n",
    "\n",
    "    @property\n",
    "    def amplitude2(self):\n",
    "        return self.raw_amplitude2_constraint.transform(self.raw_amplitude2)\n",
    "\n",
    "    @property\n",
    "    def scale1(self):\n",
    "        return self.raw_scale1_constraint.transform(self.raw_scale1)\n",
    "\n",
    "    @property\n",
    "    def scale2(self):\n",
    "        return self.raw_scale2_constraint.transform(self.raw_scale2)\n",
    "\n",
    "    @property\n",
    "    def offset(self):\n",
    "        return self.raw_offset_constraint.transform(self.raw_offset)\n",
    "\n",
    "    # Setters for parameters\n",
    "    def _set_amplitude1(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.tensor(value)\n",
    "        self.initialize(raw_amplitude1=self.raw_amplitude1_constraint.inverse_transform(value))\n",
    "\n",
    "    def _set_amplitude2(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.tensor(value)\n",
    "        self.initialize(raw_amplitude2=self.raw_amplitude2_constraint.inverse_transform(value))\n",
    "\n",
    "    def _set_scale1(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.tensor(value)\n",
    "        self.initialize(raw_scale1=self.raw_scale1_constraint.inverse_transform(value))\n",
    "\n",
    "    def _set_scale2(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.tensor(value)\n",
    "        self.initialize(raw_scale2=self.raw_scale2_constraint.inverse_transform(value))\n",
    "\n",
    "    def _set_offset(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.tensor(value)\n",
    "        self.initialize(raw_offset=self.raw_offset_constraint.inverse_transform(value))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.ndimension() == 1:\n",
    "            x = x.unsqueeze(-1)\n",
    "\n",
    "        # First exponential term (similar to original Ackley function)\n",
    "        squared_sum = torch.sum(x**2, dim=-1)\n",
    "        exp_term1 = -self.amplitude1 * torch.exp(-self.scale1 * torch.sqrt(squared_sum))\n",
    "\n",
    "        # Second term capturing periodic behavior\n",
    "        cos_term = torch.cos(2 * np.pi * x.squeeze(-1))\n",
    "        exp_term2 = -self.amplitude2 * torch.exp(self.scale2 * cos_term)\n",
    "\n",
    "        return exp_term1 + exp_term2 + self.offset\n",
    "\n",
    "def plot_mean_function(mean_module, x_range=(-2, 2), n_points=100):\n",
    "    \"\"\"\n",
    "    Plot the mean function over a specified range.\n",
    "\n",
    "    Args:\n",
    "        mean_module: The AckleyMean instance\n",
    "        x_range: Tuple of (min_x, max_x)\n",
    "        n_points: Number of points to evaluate\n",
    "    \"\"\"\n",
    "    # Create evaluation points\n",
    "    x = np.linspace(x_range[0], x_range[1], n_points)\n",
    "    x_tensor = torch.tensor(x, dtype=torch.float64).reshape(-1, 1)\n",
    "\n",
    "    # Evaluate mean function\n",
    "    with torch.no_grad():\n",
    "        mean_values = mean_module(x_tensor).numpy()\n",
    "\n",
    "    # Create figure\n",
    "    plt.figure(figsize=(12, 7))\n",
    "\n",
    "    # Plot mean function\n",
    "    plt.plot(x, mean_values, 'b-', label='Mean Function', linewidth=2)\n",
    "\n",
    "    # Plot true function for comparison\n",
    "    true_y = np.array([func(xi) for xi in x])\n",
    "    plt.plot(x, true_y, 'r--', label='True Function', linewidth=2)\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('x', fontsize=12)\n",
    "    plt.ylabel('y', fontsize=12)\n",
    "    plt.title('Ackley Mean Function vs True Function', fontsize=14)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # Show parameter values\n",
    "    param_text = 'Parameters:\\n'\n",
    "    param_text += f'Amplitude1: {mean_module.amplitude1.item():.3f}\\n'\n",
    "    param_text += f'Amplitude2: {mean_module.amplitude2.item():.3f}\\n'\n",
    "    param_text += f'Scale1: {mean_module.scale1.item():.3f}\\n'\n",
    "    param_text += f'Scale2: {mean_module.scale2.item():.3f}\\n'\n",
    "    param_text += f'Offset: {mean_module.offset.item():.3f}'\n",
    "\n",
    "    # Add parameter text box\n",
    "    plt.text(0.02, 0.98, param_text,\n",
    "             transform=plt.gca().transAxes,\n",
    "             verticalalignment='top',\n",
    "             fontsize=10,\n",
    "             bbox=dict(boxstyle='round',\n",
    "                      facecolor='white',\n",
    "                      edgecolor='gray',\n",
    "                      alpha=0.9))\n",
    "\n",
    "    # # Add components plot\n",
    "    # plt.figure(figsize=(12, 7))\n",
    "\n",
    "    # # Evaluate individual components\n",
    "    # with torch.no_grad():\n",
    "    #     # First exponential term\n",
    "    #     squared_sum = torch.sum(x_tensor**2, dim=-1)\n",
    "    #     exp_term1 = -mean_module.amplitude1 * torch.exp(-mean_module.scale1 * torch.sqrt(squared_sum))\n",
    "\n",
    "    #     # Second (periodic) term\n",
    "    #     cos_term = torch.cos(2 * np.pi * x_tensor.squeeze(-1))\n",
    "    #     exp_term2 = -mean_module.amplitude2 * torch.exp(mean_module.scale2 * cos_term)\n",
    "\n",
    "    #     # Offset term\n",
    "    #     offset = mean_module.offset * torch.ones_like(x_tensor.squeeze(-1))\n",
    "\n",
    "    # # Plot components\n",
    "    # plt.plot(x, exp_term1.numpy(), 'g-', label='Exponential Component', linewidth=2)\n",
    "    # plt.plot(x, exp_term2.numpy(), 'm-', label='Periodic Component', linewidth=2)\n",
    "    # plt.plot(x, offset.numpy() * np.ones_like(x), 'c-', label='Offset', linewidth=2)\n",
    "    # plt.plot(x, mean_values, 'b-', label='Combined Mean Function', linewidth=2)\n",
    "    # plt.plot(x, true_y, 'r--', label='True Function', linewidth=2)\n",
    "\n",
    "    # plt.xlabel('x', fontsize=12)\n",
    "    # plt.ylabel('y', fontsize=12)\n",
    "    # plt.title('Mean Function Components', fontsize=14)\n",
    "    # plt.legend(fontsize=10)\n",
    "    # plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Create and plot mean function\n",
    "mean_module = AckleyMean()\n",
    "plot_mean_function(mean_module)\n",
    "# plot_mean_evolution(mean_module, n_steps=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-v_FuGB9z84"
   },
   "source": [
    "### 2b(ii). Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kcKhhqkT9z84"
   },
   "outputs": [],
   "source": [
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.transforms import Standardize, Normalize\n",
    "# from gpytorch.kernels import RBFKernel, ScaleKernel\n",
    "from gpytorch.kernels import  ScaleKernel\n",
    "\n",
    "from gpytorch.constraints import GreaterThan\n",
    "\n",
    "class CustomGP(SingleTaskGP):\n",
    "    def __init__(self, train_X, train_Y, kernel, lengthscale_prior, outputscale_prior, noise_prior):\n",
    "        super().__init__(\n",
    "            train_X,\n",
    "            train_Y,\n",
    "            input_transform=Normalize(d=1),\n",
    "            outcome_transform=Standardize(m=1)\n",
    "        )\n",
    "\n",
    "        # Replace default mean module with custom mean\n",
    "        # self.mean_module = CustomMean()\n",
    "        self.mean_module = AckleyMean()\n",
    "\n",
    "        # Replace default kernel with custom kernel\n",
    "        self.covar_module = ScaleKernel(kernel)\n",
    "\n",
    "        # Register priors\n",
    "        self.covar_module.base_kernel.register_prior(\n",
    "            \"lengthscale_prior\",\n",
    "            lengthscale_prior,\n",
    "            lambda module: module.lengthscale,\n",
    "            lambda module, value: module._set_lengthscale(value)\n",
    "        )\n",
    "\n",
    "        self.covar_module.register_prior(\n",
    "            \"outputscale_prior\",\n",
    "            outputscale_prior,\n",
    "            lambda module: module.outputscale\n",
    "        )\n",
    "\n",
    "        self.likelihood.register_prior(\n",
    "            \"noise_prior\",\n",
    "            noise_prior,\n",
    "            lambda module: module.noise\n",
    "        )\n",
    "\n",
    "        self.likelihood.noise_covar.register_constraint(\"raw_noise\", GreaterThan(1e-5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q80i8-9z9z84"
   },
   "source": [
    "### 2c(iii). Register kerne-priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 783,
     "status": "ok",
     "timestamp": 1736877633886,
     "user": {
      "displayName": "Utkarsh Pratiush",
      "userId": "14303792046592850693"
     },
     "user_tz": -330
    },
    "id": "leXQkiNF9z85",
    "outputId": "620bfafe-f581-456b-9510-5066ef8e26e3"
   },
   "outputs": [],
   "source": [
    "### more kernel's to try\n",
    "class RBFKernel(gpytorch.kernels.Kernel):\n",
    "    is_stationary = True\n",
    "\n",
    "    def __init__(self, variance_prior=None, length_prior=None,\n",
    "                 variance_constraint=None, length_constraint=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Register raw parameters\n",
    "        self.register_parameter(\n",
    "            name='raw_lengthscale',  # Changed from raw_length to raw_lengthscale\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name='raw_variance',\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "\n",
    "        # Set constraints\n",
    "        if length_constraint is None:\n",
    "            length_constraint = Positive()\n",
    "        if variance_constraint is None:\n",
    "            variance_constraint = Positive()\n",
    "\n",
    "        self.register_constraint(\"raw_lengthscale\", length_constraint)\n",
    "        self.register_constraint(\"raw_variance\", variance_constraint)\n",
    "\n",
    "        # Set priors if any\n",
    "        if length_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"lengthscale_prior\",  # Changed from length_prior to lengthscale_prior\n",
    "                length_prior,\n",
    "                lambda m: m.lengthscale,  # Changed from length to lengthscale\n",
    "                lambda m, v: m._set_lengthscale(v),  # Changed from _set_length\n",
    "            )\n",
    "        if variance_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"variance_prior\",\n",
    "                variance_prior,\n",
    "                lambda m: m.variance,\n",
    "                lambda m, v: m._set_variance(v),\n",
    "            )\n",
    "\n",
    "    # Lengthscale property\n",
    "    @property\n",
    "    def lengthscale(self):  # Changed from length to lengthscale\n",
    "        return self.raw_lengthscale_constraint.transform(self.raw_lengthscale)\n",
    "\n",
    "    @lengthscale.setter\n",
    "    def lengthscale(self, value):\n",
    "        return self._set_lengthscale(value)\n",
    "\n",
    "    def _set_lengthscale(self, value):  # Changed from _set_length\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_lengthscale)\n",
    "        self.initialize(raw_lengthscale=self.raw_lengthscale_constraint.inverse_transform(value))\n",
    "\n",
    "    # Variance property\n",
    "    @property\n",
    "    def variance(self):\n",
    "        return self.raw_variance_constraint.transform(self.raw_variance)\n",
    "\n",
    "    @variance.setter\n",
    "    def variance(self, value):\n",
    "        return self._set_variance(value)\n",
    "\n",
    "    def _set_variance(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_variance)\n",
    "        self.initialize(raw_variance=self.raw_variance_constraint.inverse_transform(value))\n",
    "\n",
    "    def forward(self, x1, x2, **params):\n",
    "        dist = self.covar_dist(x1, x2, **params)\n",
    "        scaled_dist = dist.div(self.lengthscale)\n",
    "        return self.variance * torch.exp(-0.5 * scaled_dist.pow(2))\n",
    "\n",
    "class Matern52Kernel(gpytorch.kernels.Kernel):\n",
    "    is_stationary = True\n",
    "\n",
    "    def __init__(self, variance_prior=None, length_prior=None,\n",
    "                 variance_constraint=None, length_constraint=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Register raw parameters\n",
    "        self.register_parameter(\n",
    "            name='raw_lengthscale',\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name='raw_variance',\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "\n",
    "        # Set constraints\n",
    "        if length_constraint is None:\n",
    "            length_constraint = Positive()\n",
    "        if variance_constraint is None:\n",
    "            variance_constraint = Positive()\n",
    "\n",
    "        self.register_constraint(\"raw_lengthscale\", length_constraint)\n",
    "        self.register_constraint(\"raw_variance\", variance_constraint)\n",
    "\n",
    "        # Set priors if any\n",
    "        if length_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"lengthscale_prior\",\n",
    "                length_prior,\n",
    "                lambda m: m.lengthscale,\n",
    "                lambda m, v: m._set_lengthscale(v),\n",
    "            )\n",
    "        if variance_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"variance_prior\",\n",
    "                variance_prior,\n",
    "                lambda m: m.variance,\n",
    "                lambda m, v: m._set_variance(v),\n",
    "            )\n",
    "\n",
    "    # Lengthscale property\n",
    "    @property\n",
    "    def lengthscale(self):\n",
    "        return self.raw_lengthscale_constraint.transform(self.raw_lengthscale)\n",
    "\n",
    "    @lengthscale.setter\n",
    "    def lengthscale(self, value):\n",
    "        return self._set_lengthscale(value)\n",
    "\n",
    "    def _set_lengthscale(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_lengthscale)\n",
    "        self.initialize(raw_lengthscale=self.raw_lengthscale_constraint.inverse_transform(value))\n",
    "\n",
    "    # Variance property\n",
    "    @property\n",
    "    def variance(self):\n",
    "        return self.raw_variance_constraint.transform(self.raw_variance)\n",
    "\n",
    "    @variance.setter\n",
    "    def variance(self, value):\n",
    "        return self._set_variance(value)\n",
    "\n",
    "    def _set_variance(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_variance)\n",
    "        self.initialize(raw_variance=self.raw_variance_constraint.inverse_transform(value))\n",
    "\n",
    "    def forward(self, x1, x2, **params):\n",
    "        dist = self.covar_dist(x1, x2, **params)\n",
    "        scaled_dist = dist.div(self.lengthscale)\n",
    "\n",
    "        # Matern 5/2 formula\n",
    "        sqrt_5 = math.sqrt(5.0)\n",
    "        scaled_dist_5_3 = scaled_dist * sqrt_5\n",
    "\n",
    "        return self.variance * (1.0 + scaled_dist_5_3 + (5.0/3.0) * scaled_dist.pow(2)) * \\\n",
    "               torch.exp(-scaled_dist_5_3)\n",
    "\n",
    "class PeriodicKernel(gpytorch.kernels.Kernel):\n",
    "    is_stationary = True\n",
    "\n",
    "    def __init__(self, period_prior=None, length_prior=None, variance_prior=None,\n",
    "                 period_constraint=None, length_constraint=None, variance_constraint=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # Register raw parameters\n",
    "        self.register_parameter(\n",
    "            name='raw_period',\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name='raw_lengthscale',\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "        self.register_parameter(\n",
    "            name='raw_variance',\n",
    "            parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, 1))\n",
    "        )\n",
    "\n",
    "        # Set constraints\n",
    "        if period_constraint is None:\n",
    "            period_constraint = Positive()\n",
    "        if length_constraint is None:\n",
    "            length_constraint = Positive()\n",
    "        if variance_constraint is None:\n",
    "            variance_constraint = Positive()\n",
    "\n",
    "        self.register_constraint(\"raw_period\", period_constraint)\n",
    "        self.register_constraint(\"raw_lengthscale\", length_constraint)\n",
    "        self.register_constraint(\"raw_variance\", variance_constraint)\n",
    "\n",
    "        # Set priors if any\n",
    "        if period_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"period_prior\",\n",
    "                period_prior,\n",
    "                lambda m: m.period,\n",
    "                lambda m, v: m._set_period(v),\n",
    "            )\n",
    "        if length_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"lengthscale_prior\",\n",
    "                length_prior,\n",
    "                lambda m: m.lengthscale,\n",
    "                lambda m, v: m._set_lengthscale(v),\n",
    "            )\n",
    "        if variance_prior is not None:\n",
    "            self.register_prior(\n",
    "                \"variance_prior\",\n",
    "                variance_prior,\n",
    "                lambda m: m.variance,\n",
    "                lambda m, v: m._set_variance(v),\n",
    "            )\n",
    "\n",
    "    # Period property\n",
    "    @property\n",
    "    def period(self):\n",
    "        return self.raw_period_constraint.transform(self.raw_period)\n",
    "\n",
    "    @period.setter\n",
    "    def period(self, value):\n",
    "        return self._set_period(value)\n",
    "\n",
    "    def _set_period(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_period)\n",
    "        self.initialize(raw_period=self.raw_period_constraint.inverse_transform(value))\n",
    "\n",
    "    # Lengthscale property\n",
    "    @property\n",
    "    def lengthscale(self):\n",
    "        return self.raw_lengthscale_constraint.transform(self.raw_lengthscale)\n",
    "\n",
    "    @lengthscale.setter\n",
    "    def lengthscale(self, value):\n",
    "        return self._set_lengthscale(value)\n",
    "\n",
    "    def _set_lengthscale(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_lengthscale)\n",
    "        self.initialize(raw_lengthscale=self.raw_lengthscale_constraint.inverse_transform(value))\n",
    "\n",
    "    # Variance property\n",
    "    @property\n",
    "    def variance(self):\n",
    "        return self.raw_variance_constraint.transform(self.raw_variance)\n",
    "\n",
    "    @variance.setter\n",
    "    def variance(self, value):\n",
    "        return self._set_variance(value)\n",
    "\n",
    "    def _set_variance(self, value):\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_variance)\n",
    "        self.initialize(raw_variance=self.raw_variance_constraint.inverse_transform(value))\n",
    "\n",
    "    def forward(self, x1, x2, **params):\n",
    "        dist = self.covar_dist(x1, x2, **params)\n",
    "        # Periodic kernel formula: k(x,x') = σ² * exp(-2 * sin²(π|x-x'|/p) / ℓ²)\n",
    "        scaled_sin = torch.sin(math.pi * dist / self.period)\n",
    "        exp_term = -2 * (scaled_sin ** 2) / (self.lengthscale ** 2)\n",
    "        return self.variance * torch.exp(exp_term)\n",
    "\n",
    "\n",
    "\n",
    "## define priors\n",
    "from gpytorch.priors import GammaPrior, NormalPrior\n",
    "from gpytorch.priors import UniformPrior, LogNormalPrior, HalfNormalPrior, NormalPrior\n",
    "from gpytorch.constraints import Interval\n",
    "\n",
    "lengthscale_prior = UniformPrior(0.10, 0.5)# length scale in RBF kernel\n",
    "outputscale_prior = LogNormalPrior(0, 1)# Variance in RBF kernel\n",
    "# noise_prior = HalfNormalPrior(0.01, 1)\n",
    "noise_prior = NormalPrior(0, 0.1)\n",
    "length_constraint = Interval(0.10, 0.5)  # Matching constraint to lengthscale_prior distribution support , kernel length often need constraints (e.g., positive values) -\n",
    "\n",
    "# kernel = RBFKernel(length_prior=lengthscale_prior,\n",
    "#                    length_constraint=length_constraint\n",
    "#                    )\n",
    "kernel = Matern52Kernel(length_prior=lengthscale_prior,\n",
    "                   length_constraint=length_constraint\n",
    "                   )\n",
    "# kernel = PeriodicKernel(length_prior=lengthscale_prior,\n",
    "#                    length_constraint=length_constraint\n",
    "#                    )\n",
    "\n",
    "## more priors: GammaPrior, HalfCauchyPrior, LKJCovariancePrior, MultivariateNormalPrior, NormalPrior, SmoothedBoxPrior, UniformPrior, LogNormalPrior\n",
    "\n",
    "# Generate samples\n",
    "num_samples = 10000\n",
    "samples = noise_prior.sample(torch.Size([num_samples]))\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Histogram of samples\n",
    "plt.hist(samples.numpy(), bins=50, density=True, alpha=0.6, color='blue', label='Samples')\n",
    "\n",
    "# Generate points for the PDF\n",
    "x = np.linspace(0, 1, 1000)\n",
    "pdf = noise_prior.log_prob(torch.tensor(x)).exp()\n",
    "plt.plot(x, pdf, 'r-', lw=2, label='PDF')\n",
    "\n",
    "plt.title('Noise prior')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2rep5q8h9z85"
   },
   "source": [
    "### 2d(iv). Active learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 14444,
     "status": "ok",
     "timestamp": 1736877664254,
     "user": {
      "displayName": "Utkarsh Pratiush",
      "userId": "14303792046592850693"
     },
     "user_tz": -330
    },
    "id": "HRwfIiMW9z85",
    "outputId": "f5eecc38-124e-4268-9bfe-7bd81b0e7e8d"
   },
   "outputs": [],
   "source": [
    "# Create discrete grid\n",
    "x_points = torch.linspace(-2, 2, 50, dtype=torch.double)\n",
    "discrete_points = x_points.unsqueeze(-1)\n",
    "\n",
    "# Initial training data\n",
    "n_train = 2\n",
    "train_indices = torch.randperm(len(discrete_points))[:n_train]\n",
    "X = discrete_points[train_indices]\n",
    "# y = torch.tensor(measure(X), dtype=torch.double)\n",
    "y = torch.tensor(measure(X, noise=0), dtype=torch.double)\n",
    "\n",
    "\n",
    "n_iterations = 10\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.acquisition import ExpectedImprovement\n",
    "from botorch.optim import optimize_acqf_discrete\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.acquisition import UpperConfidenceBound\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "for step in range(n_iterations):\n",
    "    # Fit GP\n",
    "    model = CustomGP(X, y, kernel, lengthscale_prior, outputscale_prior, noise_prior)\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    fit_gpytorch_mll(mll)\n",
    "    print_detailed_model_parameters(model)\n",
    "\n",
    "\n",
    "    # Define acquisition function\n",
    "    # EI = ExpectedImprovement(model=model, best_f=y.min())\n",
    "    # UCB = UpperConfidenceBound(model=model, beta=0)  # beta controls exploration vs exploitation\n",
    "    # Define acquisition function\n",
    "    acq_func = UpperConfidenceBound(model=model, beta = 1e6 ) #--> higher beta maximum uncertanity\n",
    "    # Get remaining points (exclude training points)\n",
    "    mask = torch.ones(len(discrete_points), dtype=torch.bool)\n",
    "    mask[train_indices] = False\n",
    "    available_points = discrete_points[mask]\n",
    "\n",
    "    # Optimize acquisition function discretely\n",
    "    candidate, acq_value = optimize_acqf_discrete(\n",
    "        acq_function=acq_func,\n",
    "        q=1,\n",
    "        choices=available_points,\n",
    "        unique=True,\n",
    "    )\n",
    "\n",
    "    # Plot\n",
    "    plot_step(model, X, y, candidate, acq_func, discrete_points, step + 1)\n",
    "\n",
    "    # Update data\n",
    "    X = torch.cat([X, candidate])\n",
    "    y_new = torch.tensor([[measure(candidate.item(), noise=0)]], dtype=torch.double)\n",
    "\n",
    "    y = torch.cat([y, y_new])\n",
    "\n",
    "    # Update training indices\n",
    "    new_idx = torch.where((discrete_points == candidate).all(dim=1))[0]\n",
    "    train_indices = torch.cat([train_indices, new_idx])\n",
    "\n",
    "print(\"\\nOptimization completed!\")\n",
    "print(f\"Best observed value: {y.min().detach().item():.3f}\")\n",
    "print(f\"At location: {X[y.argmin()].detach().item():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zHjIUKkD9NHJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "yaHz4Y58lzKx",
    "nr7Y11r5CuC4",
    "NuENb5_eCyPg",
    "4Qv9tpGCab0E",
    "nxMaENIclvNX",
    "S_XbwbO9ahCz",
    "K6qw6rvVlvNX",
    "0579Zy7q7rT0",
    "zfVZ1pk17wHY",
    "Do_Yvt-n77wE",
    "smfuomEU8CYm",
    "x3PD3a7g8plI",
    "59VSmpyD9z82"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda-boactivemat]",
   "language": "python",
   "name": "conda-env-.conda-boactivemat-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
