{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49c7d93e",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/utkarshp1161/Active-learning-in-microscopy/blob/main/notebooks/GP_&_sGP_beyond_1D.ipynb)\n",
    "# GP and sGP in beyond 1 dimensions with Scalar Output using GPyTorch and BoTorch\n",
    "\n",
    "This notebook demonstrates implementation of Gaussian Process regression for N-dimensional inputs with scalar outputs, using GPyTorch for GP modeling and BoTorch for Bayesian Optimization.\n",
    "\n",
    "- Rewritten in Gpytorch and Botorch by [Utkarsh Pratiush](https://github.com/utkarshp1161). Inspired from [Original implementation in Gpax](https://github.com/SergeiVKalinin/ACerS_AE_2024/blob/main/12_GPax_beyond_1D.ipynb) by [Maxim Ziatdinov](https://github.com/ziatdinovmax) and [SVK](https://github.com/SergeiVKalinin).\n",
    "\n",
    "## Key Features:\n",
    "- N-dimensional input space handling\n",
    "- Custom mean and kernel functions\n",
    "- Bayesian Optimization with Upper Confidence Bound (UCB)\n",
    "- Visualization for 1D and 2D cases\n",
    "\n",
    "\n",
    "\n",
    "Note: For optimal performance, running on a GPU is recommended for high-dimensional problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e14c0b1",
   "metadata": {},
   "source": [
    "## 1a. Install and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36fcfc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install\n",
    "!pip install -q botorch==0.12.0\n",
    "!pip install -q gpytorch==1.13\n",
    "\n",
    "# Imports\n",
    "import torch\n",
    "import gpytorch\n",
    "import botorch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from botorch.models import SingleTaskGP\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.optim import optimize_acqf_discrete\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99e4f81",
   "metadata": {},
   "source": [
    "# 1b. Ground truth function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aee808d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test function\n",
    "def test_function(X, ndim=2):\n",
    "    \"\"\"\n",
    "    Branin-like function generalized to n dimensions\n",
    "    Args:\n",
    "        X: Input tensor of shape (n_points, ndim)\n",
    "        ndim: Number of input dimensions\n",
    "    Returns:\n",
    "        Y: Output tensor of shape (n_points, 1)\n",
    "    \"\"\"\n",
    "    if ndim == 1:\n",
    "        return (X[:, 0]**2 - 10*torch.cos(2*np.pi*X[:, 0]) + 10).unsqueeze(-1)\n",
    "    \n",
    "    # For higher dimensions, sum of modified Branin functions\n",
    "    y = torch.zeros(X.shape[0], 1)\n",
    "    for i in range(0, ndim-1, 2):\n",
    "        x1, x2 = X[:, i], X[:, i+1]\n",
    "        term1 = x2 - 5.1/(4*np.pi**2)*x1**2 + 5/np.pi*x1 - 6\n",
    "        term2 = 10*(1-1/(8*np.pi))*torch.cos(x1)\n",
    "        y = y + (term1**2 + term2 + 10).unsqueeze(-1)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416a4adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_ground_truth_function(func, ndim=2, resolution=50):\n",
    "    \"\"\"\n",
    "    Visualize function in 1D, 2D, and 3D side by side\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    \n",
    "    # 1D Visualization\n",
    "    plt.subplot(131)\n",
    "    x = np.linspace(-5, 5, resolution)\n",
    "    y = func(torch.tensor(x.reshape(-1, 1)).float(), ndim=1)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(\"1D Visualization\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"f(x)\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # 2D Visualization\n",
    "    plt.subplot(132)\n",
    "    x = np.linspace(-5, 5, resolution)\n",
    "    y = np.linspace(-5, 5, resolution)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    points = np.column_stack((X.flatten(), Y.flatten()))\n",
    "    Z = func(torch.tensor(points).float())\n",
    "    Z = Z.reshape(resolution, resolution).numpy()\n",
    "    \n",
    "    plt.contour(X, Y, Z, levels=20)\n",
    "    plt.colorbar()\n",
    "    plt.title(\"2D Visualization\")\n",
    "    plt.xlabel(\"x1\")\n",
    "    plt.ylabel(\"x2\")\n",
    "    \n",
    "    # 3D Visualization\n",
    "    ax = plt.subplot(133, projection='3d')\n",
    "    surf = ax.plot_surface(X, Y, Z, cmap='viridis')\n",
    "    plt.colorbar(surf)\n",
    "    ax.set_title(\"3D Visualization\")\n",
    "    ax.set_xlabel(\"x1\")\n",
    "    ax.set_ylabel(\"x2\")\n",
    "    ax.set_zlabel(\"f(x)\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Visualize\n",
    "visualize_ground_truth_function(test_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04de51a2",
   "metadata": {},
   "source": [
    "# 1c. Define kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d671b16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## kernel\n",
    "# Define the custom kernel\n",
    "class CustomKernel(gpytorch.kernels.Kernel):\n",
    "    def __init__(self, input_dim, lengthscale_prior=None, outputscale_prior=None):\n",
    "        super().__init__()\n",
    "        self.base_kernel = gpytorch.kernels.RBFKernel(\n",
    "            ard_num_dims=input_dim,\n",
    "            lengthscale_prior=lengthscale_prior\n",
    "        )\n",
    "        self.scaling_kernel = gpytorch.kernels.ScaleKernel(\n",
    "            self.base_kernel,\n",
    "            outputscale_prior=outputscale_prior\n",
    "        )\n",
    "        \n",
    "    def forward(self, x1, x2, **params):\n",
    "        return self.scaling_kernel.forward(x1, x2, **params)\n",
    "\n",
    "# Create sample data\n",
    "x = torch.linspace(-3, 3, 100).view(-1, 1)\n",
    "kernel = CustomKernel(input_dim=1)\n",
    "\n",
    "# Compute kernel matrix\n",
    "K = kernel(x, x).evaluate().detach().numpy()\n",
    "\n",
    "# Plot the kernel matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(K, cmap='viridis')\n",
    "plt.colorbar(label='Kernel value')\n",
    "plt.title('Custom Kernel Matrix')\n",
    "plt.xlabel('Index i')\n",
    "plt.ylabel('Index j')\n",
    "plt.show()\n",
    "\n",
    "# Plot a slice of the kernel\n",
    "x0 = torch.zeros(1, 1)\n",
    "k_slice = kernel(x, x0).evaluate().detach().numpy()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x.numpy(), k_slice)\n",
    "plt.title('Kernel Slice (k(x, 0))')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('k(x, 0)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40ebcd3",
   "metadata": {},
   "source": [
    "# 1d. GP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06f94a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.models import ExactGP\n",
    "from gpytorch.means import ConstantMean\n",
    "\n",
    "class SimpleGP(SingleTaskGP):\n",
    "    def __init__(self, train_X, train_Y, covar_module, likelihood):\n",
    "        super().__init__(train_X, train_Y)\n",
    "        self.mean_module = ConstantMean()  # Constant mean function\n",
    "        self.covar_module = covar_module\n",
    "        self.likelihood = likelihood\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# Sample points function remains the same\n",
    "def sample_points(ndim, n_points, bounds=(-5, 5)):\n",
    "    return torch.rand(n_points, ndim) * (bounds[1] - bounds[0]) + bounds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46a5a33",
   "metadata": {},
   "source": [
    "# 1e. Plotting utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ae3663d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_step(model, train_X, train_Y, next_point=None, ndim=2):\n",
    "    \"\"\"Plot current state of optimization\"\"\"\n",
    "    if ndim > 2:\n",
    "        print(\"Visualization only supported for 1D and 2D inputs\")\n",
    "        return\n",
    "    \n",
    "    if ndim == 2:\n",
    "        # Create meshgrid\n",
    "        x1 = torch.linspace(train_X[:, 0].min(), train_X[:, 0].max(), 100)\n",
    "        x2 = torch.linspace(train_X[:, 1].min(), train_X[:, 1].max(), 100)\n",
    "        x1_grid, x2_grid = torch.meshgrid(x1, x2)\n",
    "        grid_points = torch.stack([x1_grid.flatten(), x2_grid.flatten()], dim=-1)\n",
    "        \n",
    "        # Get predictions\n",
    "        with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "            posterior = model.posterior(grid_points)\n",
    "            mean = posterior.mean.squeeze()  # Add squeeze to handle single-output case\n",
    "            lower, upper = posterior.confidence_region()\n",
    "        \n",
    "        # Reshape for plotting\n",
    "        mean_surface = mean.reshape(100, 100)\n",
    "        std_surface = ((upper - lower) / 2).reshape(100, 100)\n",
    "        true_values = test_function(grid_points, ndim).reshape(100, 100)\n",
    "        \n",
    "        # Create plots\n",
    "        fig = plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        # True function\n",
    "        ax1 = fig.add_subplot(131)\n",
    "        c1 = ax1.contourf(x1_grid, x2_grid, true_values, levels=20)\n",
    "        plt.colorbar(c1, ax=ax1)\n",
    "        ax1.set_title('True Function')\n",
    "        ax1.scatter(train_X[:, 0], train_X[:, 1], c='red', marker='x', label='Training points')\n",
    "        if next_point is not None and next_point.numel() > 0:  # Check if next_point exists and is not empty\n",
    "            ax1.scatter(next_point[0, 0], next_point[0, 1], c='green', marker='o', s=100, label='Next point')\n",
    "        ax1.legend()\n",
    "        \n",
    "        # Posterior mean\n",
    "        ax2 = fig.add_subplot(132)\n",
    "        c2 = ax2.contourf(x1_grid, x2_grid, mean_surface, levels=20)\n",
    "        plt.colorbar(c2, ax=ax2)\n",
    "        ax2.set_title('Posterior Mean')\n",
    "        ax2.scatter(train_X[:, 0], train_X[:, 1], c='red', marker='x')\n",
    "        if next_point is not None and next_point.numel() > 0:\n",
    "            ax2.scatter(next_point[0, 0], next_point[0, 1], c='green', marker='o', s=100)\n",
    "        \n",
    "        # Posterior std\n",
    "        ax3 = fig.add_subplot(133)\n",
    "        c3 = ax3.contourf(x1_grid, x2_grid, std_surface, levels=20)\n",
    "        plt.colorbar(c3, ax=ax3)\n",
    "        ax3.set_title('Posterior Std Dev')\n",
    "        ax3.scatter(train_X[:, 0], train_X[:, 1], c='red', marker='x')\n",
    "        if next_point is not None and next_point.numel() > 0:\n",
    "            ax3.scatter(next_point[0, 0], next_point[0, 1], c='green', marker='o', s=100)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    elif ndim == 1:\n",
    "        x_plot = torch.linspace(train_X.min(), train_X.max(), 100).reshape(-1, 1)\n",
    "        \n",
    "        with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "            posterior = model.posterior(x_plot)\n",
    "            mean = posterior.mean.squeeze()\n",
    "            lower, upper = posterior.confidence_region()\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(x_plot.numpy(), mean.numpy(), 'b-', label='Posterior Mean')\n",
    "        plt.fill_between(x_plot.numpy().flatten(), \n",
    "                        lower.numpy(), \n",
    "                        upper.numpy(), \n",
    "                        alpha=0.2, \n",
    "                        label='95% Confidence')\n",
    "        plt.scatter(train_X.numpy(), train_Y.numpy(), c='red', \n",
    "                    marker='x', label='Training Points')\n",
    "        if next_point is not None and next_point.numel() > 0:\n",
    "            next_y = test_function(next_point, ndim)\n",
    "            plt.scatter(next_point.numpy(), next_y.numpy(), \n",
    "                       c='green', marker='o', s=100, label='Next point')\n",
    "        plt.legend()\n",
    "        plt.title('GP Posterior')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7bd046",
   "metadata": {},
   "source": [
    "# 1f. Training GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc235126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    ndim = 2\n",
    "    n_initial = 10\n",
    "    n_test = 100\n",
    "    \n",
    "    # Generate initial data\n",
    "    train_X = sample_points(ndim, n_initial)\n",
    "    train_Y = test_function(train_X, ndim)\n",
    "    \n",
    "    # Define priors\n",
    "    lengthscale_prior = gpytorch.priors.GammaPrior(3.0, 6.0)\n",
    "    outputscale_prior = gpytorch.priors.GammaPrior(2.0, 0.15)\n",
    "    noise_prior = gpytorch.priors.GammaPrior(1.1, 0.05)\n",
    "    \n",
    "    # Define model components\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood(noise_prior=noise_prior)\n",
    "    covar_module = CustomKernel(\n",
    "        ndim,\n",
    "        lengthscale_prior=lengthscale_prior,\n",
    "        outputscale_prior=outputscale_prior\n",
    "    )\n",
    "    \n",
    "    # Initialize and fit model\n",
    "    model = SimpleGP(train_X, train_Y, covar_module, likelihood)\n",
    "    mll = ExactMarginalLogLikelihood(likelihood, model)\n",
    "    fit_gpytorch_mll(mll)\n",
    "    \n",
    "    plot_step(model, train_X, train_Y.squeeze(-1), next_point=None, ndim=ndim)  # Squeeze for plotting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ada7ce",
   "metadata": {},
   "source": [
    "# 2 sGP - with mean function prior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb311572",
   "metadata": {},
   "source": [
    "## 2a. Define cusom mean and sGP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6267af8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom mean function\n",
    "class CustomMean(gpytorch.means.Mean):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.constant = gpytorch.means.ConstantMean()\n",
    "        self.linear = gpytorch.means.LinearMean(input_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.constant(x) + self.linear(x)\n",
    "# Create some test data\n",
    "x = torch.linspace(-5, 5, 100).unsqueeze(-1)\n",
    "\n",
    "# Initialize the custom mean function\n",
    "mean_function = CustomMean(input_size=1)\n",
    "\n",
    "# Get predictions\n",
    "with torch.no_grad():\n",
    "    y_pred = mean_function(x)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x.numpy(), y_pred.numpy(), 'b-', label='Custom Mean Function')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Custom Mean Function Plot')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c93a5ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GP Model\n",
    "class CustomGP(SingleTaskGP):\n",
    "    def __init__(self, train_X, train_Y, mean_module, covar_module, likelihood):\n",
    "        super().__init__(train_X, train_Y)\n",
    "        self.mean_module = mean_module\n",
    "        self.covar_module = covar_module\n",
    "        self.likelihood = likelihood\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c97e880",
   "metadata": {},
   "source": [
    "## 2b. Training sGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21a777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "ndim = 2\n",
    "n_initial = 10\n",
    "n_test = 100\n",
    "\n",
    "# Generate initial data\n",
    "train_X = sample_points(ndim, n_initial)\n",
    "train_Y = test_function(train_X, ndim)\n",
    "\n",
    "# Define priors\n",
    "lengthscale_prior = gpytorch.priors.GammaPrior(3.0, 6.0)\n",
    "outputscale_prior = gpytorch.priors.GammaPrior(2.0, 0.15)\n",
    "noise_prior = gpytorch.priors.GammaPrior(1.1, 0.05)\n",
    "\n",
    "# Define model components\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood(noise_prior=noise_prior)\n",
    "mean_module = CustomMean(ndim)\n",
    "covar_module = CustomKernel(\n",
    "    ndim,\n",
    "    lengthscale_prior=lengthscale_prior,\n",
    "    outputscale_prior=outputscale_prior\n",
    ")\n",
    "\n",
    "# Initialize and fit model\n",
    "model = CustomGP(train_X, train_Y, mean_module, covar_module, likelihood)\n",
    "mll = ExactMarginalLogLikelihood(likelihood, model)\n",
    "fit_gpytorch_mll(mll)\n",
    "plot_step(model, train_X, train_Y.squeeze(-1), ndim=ndim)  # Squeeze for plotting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2b4fb4",
   "metadata": {},
   "source": [
    "# 3. Active learning with sGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075c4f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "ndim = 2\n",
    "n_initial = 10\n",
    "n_iterations = 10\n",
    "beta = 1e6### --> higher means more exploration\n",
    "\n",
    "# Generate initial data\n",
    "train_X = sample_points(ndim, n_initial)\n",
    "train_Y = test_function(train_X, ndim).unsqueeze(-1)  # Add extra dimension here --> so concatenation works fine in the loop\n",
    "\n",
    "# Generate candidate points for discrete optimization\n",
    "n_candidates = 1000\n",
    "candidates = sample_points(ndim, n_candidates)\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    # Define priors\n",
    "    lengthscale_prior = gpytorch.priors.GammaPrior(3.0, 6.0)\n",
    "    outputscale_prior = gpytorch.priors.GammaPrior(2.0, 0.15)\n",
    "    noise_prior = gpytorch.priors.GammaPrior(1.1, 0.05)\n",
    "\n",
    "    # Define model components\n",
    "    likelihood = gpytorch.likelihoods.GaussianLikelihood(noise_prior=noise_prior)\n",
    "    mean_module = CustomMean(ndim)\n",
    "    covar_module = CustomKernel(\n",
    "        ndim,\n",
    "        lengthscale_prior=lengthscale_prior,\n",
    "        outputscale_prior=outputscale_prior\n",
    "    )\n",
    "\n",
    "    # Initialize and fit model\n",
    "    model = CustomGP(train_X, train_Y.squeeze(-1), mean_module, covar_module, likelihood)  # Squeeze here for CustomGP\n",
    "    mll = ExactMarginalLogLikelihood(likelihood, model)\n",
    "    fit_gpytorch_mll(mll)\n",
    "\n",
    "    # Plot current state\n",
    "    plot_step(model, train_X, train_Y.squeeze(-1), ndim=ndim)  # Squeeze for plotting\n",
    "\n",
    "    # Define acquisition function (UCB with beta=1e6)\n",
    "    UCB = UpperConfidenceBound(model, beta=beta)\n",
    "\n",
    "    # Optimize acquisition function\n",
    "    next_point, acq_value = optimize_acqf_discrete(\n",
    "        acq_function=UCB,\n",
    "        choices=candidates,\n",
    "        q=1,\n",
    "    )\n",
    "\n",
    "    # Plot with next point\n",
    "    plot_step(model, train_X, train_Y.squeeze(-1), next_point, ndim=ndim)  # Squeeze for plotting\n",
    "\n",
    "    # Evaluate next point and update training data\n",
    "    next_value = test_function(next_point, ndim).unsqueeze(-1)  # Add extra dimension\n",
    "    train_X = torch.cat([train_X, next_point])\n",
    "    train_Y = torch.cat([train_Y, next_value])  # Now dimensions match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e35237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-boactivemat]",
   "language": "python",
   "name": "conda-env-.conda-boactivemat-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
